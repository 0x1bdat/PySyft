# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: proto/lib/syfertext/encoders/sentence_encoder.proto

# third party
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database

# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


# syft absolute
from syft.proto.lib.syfertext.tokenizers import (
    spacy_tokenizer_pb2 as proto_dot_lib_dot_syfertext_dot_tokenizers_dot_spacy__tokenizer__pb2,
)

DESCRIPTOR = _descriptor.FileDescriptor(
    name="proto/lib/syfertext/encoders/sentence_encoder.proto",
    package="syft.lib.syfertext",
    syntax="proto3",
    serialized_options=None,
    create_key=_descriptor._internal_create_key,
    serialized_pb=b'\n3proto/lib/syfertext/encoders/sentence_encoder.proto\x12\x12syft.lib.syfertext\x1a\x34proto/lib/syfertext/tokenizers/spacy_tokenizer.proto"V\n\x0fSentenceEncoder\x12\x0c\n\x04uuid\x18\x01 \x01(\x0c\x12\x35\n\ttokenizer\x18\x02 \x01(\x0b\x32".syft.lib.syfertext.SpacyTokenizerb\x06proto3',
    dependencies=[
        proto_dot_lib_dot_syfertext_dot_tokenizers_dot_spacy__tokenizer__pb2.DESCRIPTOR,
    ],
)


_SENTENCEENCODER = _descriptor.Descriptor(
    name="SentenceEncoder",
    full_name="syft.lib.syfertext.SentenceEncoder",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    create_key=_descriptor._internal_create_key,
    fields=[
        _descriptor.FieldDescriptor(
            name="uuid",
            full_name="syft.lib.syfertext.SentenceEncoder.uuid",
            index=0,
            number=1,
            type=12,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=b"",
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
        _descriptor.FieldDescriptor(
            name="tokenizer",
            full_name="syft.lib.syfertext.SentenceEncoder.tokenizer",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
            create_key=_descriptor._internal_create_key,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=129,
    serialized_end=215,
)

_SENTENCEENCODER.fields_by_name[
    "tokenizer"
].message_type = (
    proto_dot_lib_dot_syfertext_dot_tokenizers_dot_spacy__tokenizer__pb2._SPACYTOKENIZER
)
DESCRIPTOR.message_types_by_name["SentenceEncoder"] = _SENTENCEENCODER
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

SentenceEncoder = _reflection.GeneratedProtocolMessageType(
    "SentenceEncoder",
    (_message.Message,),
    {
        "DESCRIPTOR": _SENTENCEENCODER,
        "__module__": "proto.lib.syfertext.encoders.sentence_encoder_pb2"
        # @@protoc_insertion_point(class_scope:syft.lib.syfertext.SentenceEncoder)
    },
)
_sym_db.RegisterMessage(SentenceEncoder)


# @@protoc_insertion_point(module_scope)
