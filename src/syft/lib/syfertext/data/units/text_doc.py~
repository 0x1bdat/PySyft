# stdlib
from typing import List
from typing import Optional

# third party
from google.protobuf.reflection import GeneratedProtocolMessageType
from syfertext.data.units import TokenMeta

# syft relative
from .....core.store.storeable_object import StorableObject
from .....proto.lib.syfertext.data.units.text_doc_pb2 import TextDoc as TextDoc_PB
from .....proto.lib.syfertext.data.units.token_meta_pb2 import TokenMeta as TokenMeta_PB
from .....proto.lib.syfertext.data.units.attribute_values_pb2 import AttributeValues as AttributeValues_PB
from .....util import aggressive_set_attr


class TextDocWrapper(StorableObject):

    def __init__(self, value: object):

        super().__init__(
            data = value,
            id = getattr(value, 'id', UID()),
            tags = getattr(value, 'tags', []),
            description = getattr(value, 'description', '')
        )

        self.value = value

    def _data_object2proto(self) -> TokenMeta_PB:

        token_meta_pb = TokenMeta_PB()

        token_meta_pb.text = self.value.text
        token_meta_pb.space_after = self.value.space_after

        # Add the dictionary of attributes to the ProtoBuf object
        for att_name, att_values in self.value.attributes.items():
            token_meta_pb.attributes[att_name].values.extend(att_values)

            
        return spacy_tokenizer_pb

    @staticmethod
    def _data_proto2object(proto: SpacyTokenizer_PB) -> SpacyTokenizer:

        prefixes = proto.prefixes
        suffixes = proto.suffixes
        infixes = proto.infixes

        # Create a dict from the protobuf's map object representing the token
        # exceptions
        token_exceptions = dict()
        
        for token in proto.exceptions:
            token_splits = proto.exceptions[token].splits
            token_exceptions[token] = token_splits

        # Create the DefautTokenizer object
        spacy_tokenizer = SpacyTokenizer(prefixes = prefixes,
                                             suffixes = suffixes,
                                             infixes = infixes,
                                             exceptions = token_exceptions
                                             )
        
        # Create a uuid.UUID object and assign it as an attribute to the tokenizer
        # The reason I do not set the id directly in the constructor is because I
        # do not want the API to expose the ID which is not something the end user
        # should worry about.
        uuid = UUID(bytes = proto.uuid)
        spacy_tokenizer.id = UID(value = uuid)

        return spacy_tokenizer

    
    @staticmethod
    def get_data_protobuf_schema() -> GeneratedProtocolMessageType:
        return SpacyTokenizer_PB
    
    @staticmethod
    def get_wrapped_type() -> type:
        return SpacyTokenizer

    @staticmethod
    def construct_new_object(
            id: UID,
            data: StorableObject,
            description: Optional[str],
            tags: Optional[List[str]],
    ) -> StorableObject:
        
        data.id = id
        data.tags = tags
        data.description = description
        
        return data
    
aggressive_set_attr(
    obj = SpacyTokenizer,
    name = 'serializable_wrapper_type',
    attr = SpacyTokenizerWrapper
)
