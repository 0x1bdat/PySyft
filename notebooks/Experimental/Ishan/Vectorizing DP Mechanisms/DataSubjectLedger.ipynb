{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "class DataSubjectLedger:\n",
    "    \"\"\"for a particular data subject, this is the list\n",
    "    of all mechanisms releasing informationo about this\n",
    "    particular subject, stored in a vectorized form\"\"\"\n",
    "    \n",
    "    def __init__(self, default_delta=1e-6):\n",
    "        \n",
    "        self.default_delta = default_delta\n",
    "        \n",
    "        self.sigmas = np.array([])\n",
    "        self.l2_norms = np.array([])\n",
    "        self.l2_norm_bounds = np.array([])\n",
    "        self.Ls = np.array([])\n",
    "        self.coeffs = np.array([])\n",
    "        self.deltas = np.array([])\n",
    "        self.entity_ids = np.array([])\n",
    "        self.entity2budget = np.array([])\n",
    "        \n",
    "        self.cache_constant2epsilon = list()     \n",
    "        \n",
    "        for i in range(10000):\n",
    "            alpha, eps = self.get_optimal_alpha_for_constant(i+1)\n",
    "            self.cache_constant2epsilon.append(eps)\n",
    "            \n",
    "        self.cache_constant2epsilon = np.array(self.cache_constant2epsilon)        \n",
    "        \n",
    "        \n",
    "    def append_batch(self, \n",
    "                     sigmas: np.ndarray, \n",
    "                     l2_norms: np.ndarray, \n",
    "                     l2_norm_bounds: np.ndarray, \n",
    "                     Ls: np.ndarray, \n",
    "                     coeffs: np.ndarray, \n",
    "                     deltas: np.ndarray, \n",
    "                     entity_ids: np.ndarray):\n",
    "        \n",
    "        self.sigmas = np.concatenate([self.sigmas, sigmas])\n",
    "        self.l2_norms = np.concatenate([self.l2_norms, l2_norms])        \n",
    "        self.l2_norm_bounds = np.concatenate([self.l2_norm_bounds, l2_norm_bounds])        \n",
    "        self.Ls = np.concatenate([self.Ls, Ls])        \n",
    "        self.coeffs = np.concatenate([self.coeffs, coeffs])        \n",
    "        self.deltas = np.concatenate([self.deltas, deltas])        \n",
    "        self.entity_ids = np.concatenate([self.entity_ids, entity_ids])                \n",
    "        \n",
    "    def get_rdp_func(self, entity_id, private=True):\n",
    "        \n",
    "            constant = self.get_rdp_constant(entity_id=entity_id, private=private)\n",
    "            \n",
    "            def rdp_func(alpha):\n",
    "                return alpha * constant\n",
    "\n",
    "            return rdp_func  \n",
    "        \n",
    "    def get_fake_rdp_func(self, constant):\n",
    "        \n",
    "        def func(alpha):\n",
    "            return alpha * constant\n",
    "        \n",
    "        return func\n",
    "\n",
    "    def get_alpha_search_function(self, entity_id, func_override=None):\n",
    "        \n",
    "        if func_override is None:\n",
    "            rdp_compose_func = self.get_rdp_func(entity_id)\n",
    "        else:\n",
    "            rdp_compose_func = func_override\n",
    "            \n",
    "        if len(self.deltas) > 0:\n",
    "            delta = np.max(self.deltas)\n",
    "        else:\n",
    "            delta = self.default_delta\n",
    "            \n",
    "        log_delta = np.log(delta)\n",
    "        \n",
    "        def fun(alpha):  # the input is the RDP's \\alpha\n",
    "            \n",
    "            if alpha <= 1:\n",
    "                return np.inf\n",
    "            else:\n",
    "                alpha_minus_1 = alpha-1\n",
    "                return np.maximum(rdp_compose_func(alpha) + np.log(alpha_minus_1/alpha)\n",
    "                                  - (log_delta + np.log(alpha))/alpha_minus_1, 0)\n",
    "        return fun    \n",
    "    \n",
    "    def get_epsilon_spend(self, entity_ids):\n",
    "        eps_spends = list()\n",
    "                \n",
    "        for entity_id in entity_ids:\n",
    "            \n",
    "            constant = self.get_rdp_constant(entity_id=entity_id, private=True)\n",
    "            if constant == 0:\n",
    "                # when the constant is 0 it typically means no entities were found\n",
    "                # but regardless it means that the epsilon spend would be 0.\n",
    "                eps_spends.append(0.0)\n",
    "            else:\n",
    "                constant2lookup_constant = int(constant-1)\n",
    "                print(constant2lookup_constant)\n",
    "                eps_spends.append(self.cache_constant2epsilon[constant2lookup_constant])\n",
    "            \n",
    "        return eps_spends\n",
    "    \n",
    "    def get_optimal_alpha_for_constant(self, constant=3):\n",
    "        \n",
    "        f = self.get_fake_rdp_func(constant)\n",
    "        f2 = self.get_alpha_search_function(entity_id=1, func_override=f)\n",
    "        results = minimize_scalar(f2, method='Brent', bracket=(1,2), bounds=[1, np.inf])\n",
    "        \n",
    "        return results.x, results.fun\n",
    "    \n",
    "\n",
    "    def get_rdp_constant(self, entity_id, private=True):\n",
    "    \n",
    "        squared_Ls = self.Ls**2\n",
    "        squared_sigma = self.sigmas**2\n",
    "        entity_mask = self.entity_ids == entity_id\n",
    "        \n",
    "        if private:\n",
    "            \n",
    "            squared_L2_norms = self.l2_norms**2            \n",
    "            private_constant = (squared_Ls * squared_L2_norms / (2 * squared_sigma)) * entity_mask\n",
    "            private_constant = private_constant * self.coeffs\n",
    "            private_constant = np.sum(private_constant)\n",
    "            \n",
    "            return private_constant\n",
    "        else:\n",
    "            squared_L2_norm_bounds = self.l2_norms_bound**2            \n",
    "            public_constant = (squared_Ls * squared_L2_norm_bounds / (2 * squared_sigma)) * entity_mask\n",
    "            public_constant = public_constant * self.coeffs\n",
    "            public_constant = np.sum(private_constant)\n",
    "            return public_constant    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_ids_query = np.array([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_batch = np.where(np.in1d(ledger.entity_ids, entity_ids_query))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sigmas = ledger.sigmas.take(indices_batch)\n",
    "batch_Ls = ledger.Ls.take(indices_batch)\n",
    "batch_l2_norms = ledger.l2_norms.take(indices_batch)\n",
    "batch_l2_norm_bounds = ledger.l2_norm_bounds.take(indices_batch)\n",
    "batch_coeffs = ledger.coeffs.take(indices_batch)\n",
    "batch_entity_ids = ledger.entity_ids.take(indices_batch)\n",
    "\n",
    "# squared_Ls = batch_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 3., 3.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_entity_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atrask/opt/anaconda3/envs/syft/lib/python3.7/site-packages/scipy/optimize/optimize.py:2621: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  w = xb - ((xb - xc) * tmp2 - (xb - xa) * tmp1) / denom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499\n",
      "2499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2868.0555591748666, 2868.0555591748666]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ledger = DataSubjectLedger()\n",
    "\n",
    "ledger.append_batch(sigmas=np.ones(2),\n",
    "                    l2_norms=np.ones(2)*10,\n",
    "                    l2_norm_bounds=np.ones(2)*40,\n",
    "                    Ls=np.ones(2)*5,\n",
    "                    coeffs=np.ones(2),\n",
    "                    deltas=np.ones(2)*1e6,\n",
    "                    entity_ids=np.ones(2))\n",
    "\n",
    "ledger.append_batch(sigmas=np.ones(2),\n",
    "                    l2_norms=np.ones(2)*10,\n",
    "                    l2_norm_bounds=np.ones(2)*40,\n",
    "                    Ls=np.ones(2)*5,\n",
    "                    coeffs=np.ones(2),\n",
    "                    deltas=np.ones(2)*1e6,\n",
    "                    entity_ids=np.ones(2)+1)\n",
    "\n",
    "ledger.append_batch(sigmas=np.ones(2),\n",
    "                    l2_norms=np.ones(2)*10,\n",
    "                    l2_norm_bounds=np.ones(2)*40,\n",
    "                    Ls=np.ones(2)*5,\n",
    "                    coeffs=np.ones(2),\n",
    "                    deltas=np.ones(2)*1e6,\n",
    "                    entity_ids=np.ones(2)+2)\n",
    "\n",
    "\n",
    "ledger.get_epsilon_spend(entity_ids=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
