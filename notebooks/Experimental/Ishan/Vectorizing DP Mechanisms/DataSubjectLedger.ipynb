{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "class DataSubjectLedger:\n",
    "    \"\"\"for a particular data subject, this is the list\n",
    "    of all mechanisms releasing informationo about this\n",
    "    particular subject, stored in a vectorized form\"\"\"\n",
    "    \n",
    "    def __init__(self, default_delta=1e-6):\n",
    "        \n",
    "        self.default_delta = default_delta\n",
    "        self.reset()\n",
    "        self.cache_constant2epsilon = list()     \n",
    "        \n",
    "        for i in range(100000):\n",
    "            alpha, eps = self.get_optimal_alpha_for_constant(i+1)\n",
    "            self.cache_constant2epsilon.append(eps)\n",
    "            \n",
    "        self.cache_constant2epsilon = np.array(self.cache_constant2epsilon)        \n",
    "        \n",
    "\n",
    "    def reset(self):\n",
    "        self.sigmas = np.array([])\n",
    "        self.l2_norms = np.array([])\n",
    "        self.l2_norm_bounds = np.array([])\n",
    "        self.Ls = np.array([])\n",
    "        self.coeffs = np.array([])\n",
    "        self.deltas = np.array([])\n",
    "        self.entity_ids = np.array([])\n",
    "        self.entity2budget = np.array([])\n",
    "        \n",
    "    def append_batch(self, \n",
    "                     sigmas: np.ndarray, \n",
    "                     l2_norms: np.ndarray, \n",
    "                     l2_norm_bounds: np.ndarray, \n",
    "                     Ls: np.ndarray, \n",
    "                     coeffs: np.ndarray, \n",
    "                     deltas: np.ndarray, \n",
    "                     entity_ids: np.ndarray):\n",
    "        \n",
    "        self.sigmas = np.concatenate([self.sigmas, sigmas])\n",
    "        self.l2_norms = np.concatenate([self.l2_norms, l2_norms])        \n",
    "        self.l2_norm_bounds = np.concatenate([self.l2_norm_bounds, l2_norm_bounds])        \n",
    "        self.Ls = np.concatenate([self.Ls, Ls])        \n",
    "        self.coeffs = np.concatenate([self.coeffs, coeffs])        \n",
    "        self.deltas = np.concatenate([self.deltas, deltas])        \n",
    "        self.entity_ids = np.concatenate([self.entity_ids, entity_ids])                \n",
    "        \n",
    "    def get_rdp_func(self, entity_id, private=True):\n",
    "        \n",
    "            constant = self.get_rdp_constant(entity_id=entity_id, private=private)\n",
    "            \n",
    "            def rdp_func(alpha):\n",
    "                return alpha * constant\n",
    "\n",
    "            return rdp_func  \n",
    "        \n",
    "    def get_fake_rdp_func(self, constant):\n",
    "        \n",
    "        def func(alpha):\n",
    "            return alpha * constant\n",
    "        \n",
    "        return func\n",
    "\n",
    "    def get_alpha_search_function(self, entity_id, func_override=None):\n",
    "        \n",
    "        if func_override is None:\n",
    "            rdp_compose_func = self.get_rdp_func(entity_id)\n",
    "        else:\n",
    "            rdp_compose_func = func_override\n",
    "            \n",
    "        if len(self.deltas) > 0:\n",
    "            delta = np.max(self.deltas)\n",
    "        else:\n",
    "            delta = self.default_delta\n",
    "            \n",
    "        log_delta = np.log(delta)\n",
    "        \n",
    "        def fun(alpha):  # the input is the RDP's \\alpha\n",
    "            \n",
    "            if alpha <= 1:\n",
    "                return np.inf\n",
    "            else:\n",
    "                alpha_minus_1 = alpha-1\n",
    "                return np.maximum(rdp_compose_func(alpha) + np.log(alpha_minus_1/alpha)\n",
    "                                  - (log_delta + np.log(alpha))/alpha_minus_1, 0)\n",
    "        return fun    \n",
    "    \n",
    "    def get_optimal_alpha_for_constant(self, constant=3):\n",
    "        \n",
    "        f = self.get_fake_rdp_func(constant)\n",
    "        f2 = self.get_alpha_search_function(entity_id=1, func_override=f)\n",
    "        results = minimize_scalar(f2, method='Brent', bracket=(1,2), bounds=[1, np.inf])\n",
    "        \n",
    "        return results.x, results.fun\n",
    "    \n",
    "\n",
    "    def get_rdp_constant(self, entity_id, private=True):\n",
    "    \n",
    "        squared_Ls = self.Ls**2\n",
    "        squared_sigma = self.sigmas**2\n",
    "        entity_mask = self.entity_ids == entity_id\n",
    "        \n",
    "        if private:\n",
    "            \n",
    "            squared_L2_norms = self.l2_norms**2            \n",
    "            private_constant = (squared_Ls * squared_L2_norms / (2 * squared_sigma)) * entity_mask\n",
    "            private_constant = private_constant * self.coeffs\n",
    "            private_constant = np.sum(private_constant)\n",
    "            \n",
    "            return private_constant\n",
    "        else:\n",
    "            squared_L2_norm_bounds = self.l2_norms_bound**2            \n",
    "            public_constant = (squared_Ls * squared_L2_norm_bounds / (2 * squared_sigma)) * entity_mask\n",
    "            public_constant = public_constant * self.coeffs\n",
    "            public_constant = np.sum(private_constant)\n",
    "            return public_constant  \n",
    "        \n",
    "    def get_batch_rdp_constants(self, entity_ids_query, private=True):\n",
    "        \n",
    "        # get indices for all ledger rows corresponding to any of the entities in entity_ids_query\n",
    "        indices_batch = np.where(np.in1d(self.entity_ids, entity_ids_query))[0]\n",
    "        \n",
    "        # use the indices to get a \"batch\" of the full ledger. this is the only part\n",
    "        # of the ledger we care about (the entries corresponding to specific entities)\n",
    "        batch_sigmas = self.sigmas.take(indices_batch)\n",
    "        batch_Ls = self.Ls.take(indices_batch)\n",
    "        batch_l2_norms = self.l2_norms.take(indices_batch)\n",
    "        batch_l2_norm_bounds = self.l2_norm_bounds.take(indices_batch)\n",
    "        batch_coeffs = self.coeffs.take(indices_batch)\n",
    "        batch_entity_ids = self.entity_ids.take(indices_batch).astype(np.int64)\n",
    "        \n",
    "        \n",
    "        squared_Ls = batch_Ls**2\n",
    "        squared_sigma = batch_sigmas**2\n",
    "        \n",
    "        if private:\n",
    "            squared_L2_norms = batch_l2_norms**2\n",
    "            constant = (squared_Ls * squared_L2_norms / (2 * squared_sigma)) * batch_coeffs\n",
    "            constant = np.bincount(batch_entity_ids, weights=constant).take(entity_ids_query)\n",
    "            return constant\n",
    "        else:\n",
    "            squared_L2_norm_bounds = batch_l2_norm_bounds**2\n",
    "            constant = (squared_Ls * squared_L2_norm_bounds / (2 * squared_sigma)) * batch_coeffs\n",
    "            constant = np.bincount(batch_entity_ids, weights=constant).take(entity_ids_query)\n",
    "            return constant\n",
    "        \n",
    "    def get_epsilon_spend(self, entity_ids_query):\n",
    "        rdp_constants = self.get_batch_rdp_constants(entity_ids_query=entity_ids_query).astype(np.int64)\n",
    "        rdp_constants_lookup = rdp_constants - 1\n",
    "        eps_spend = self.cache_constant2epsilon.take(rdp_constants_lookup)\n",
    "        return eps_spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-a83c0441fd5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_num_threads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mkl'"
     ]
    }
   ],
   "source": [
    "import mkl\n",
    "mkl.set_num_threads(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ledger = DataSubjectLedger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ledger.reset()\n",
    "n = int(1e7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ledger.append_batch(sigmas=np.ones(n),\n",
    "                    l2_norms=np.ones(n)*10,\n",
    "                    l2_norm_bounds=np.ones(n)*40,\n",
    "                    Ls=np.random.randn(n)*5,\n",
    "                    coeffs=np.ones(n),\n",
    "                    deltas=np.ones(n)*1e6,\n",
    "                    entity_ids=np.arange(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.arange(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.6 s, sys: 8.82 s, total: 26.4 s\n",
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eps = ledger.get_epsilon_spend(entity_ids_query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.58 s, sys: 418 ms, total: 2 s\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eps = ledger.get_epsilon_spend(entity_ids_query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3725.40022315, 2263.91209203,   30.04967125, 2034.64885325,\n",
       "        159.79325645,   99.16966854,  727.20567344, 1890.65316412,\n",
       "       4849.06547809, 2601.18850134, 2072.75222106, 3372.47573355,\n",
       "        196.52083601,   32.22166095,  192.49873732,  134.48558098,\n",
       "        850.26206058, 3582.66288229,  308.96429586,  670.33884933])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2869.12969754, 7827.67597659])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
