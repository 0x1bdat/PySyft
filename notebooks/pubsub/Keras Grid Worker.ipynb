{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from grid import ipfsapi\n",
    "import base64\n",
    "import random\n",
    "import torch\n",
    "import keras\n",
    "import json\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grid(object):\n",
    "    \n",
    "    def __init__(self,ipfs_addr='127.0.0.1',port=5001):\n",
    "        \n",
    "        self.api = ipfsapi.connect(ipfs_addr, port)\n",
    "        self.encoded_id = self.get_encoded_id()\n",
    "        self.id = self.api.config_show()['Identity']['PeerID']\n",
    "        \n",
    "    def get_encoded_id(self):\n",
    "        \n",
    "        \"\"\"Currently a workaround because we can't figure out how to decode the 'from' \n",
    "        side of messages sent across the wire. However, we can check to see if two messages\n",
    "        are equal. Thus, by sending a random message to ourselves we can figure out what\n",
    "        our own encoded id is. TODO: figure out how to decode it.\"\"\"\n",
    "        \n",
    "        rand_channel = random.randint(0,1000000)\n",
    "        temp_channel = self.api.pubsub_sub(topic=rand_channel,stream=True)\n",
    "        secret = random.randint(0,1000000)\n",
    "        self.api.pubsub_pub(topic=rand_channel,payload=\"id:\" + str(secret))\n",
    "        \n",
    "        for encoded in temp_channel:\n",
    "\n",
    "            # decode message\n",
    "            decoded = self.decode_message(encoded)\n",
    "            \n",
    "            if(decoded is not None):\n",
    "                if(str(decoded['data'].split(\":\")[-1]) == str(secret)):\n",
    "                    return str(decoded['from'])\n",
    "                \n",
    "    def decode_message(self,encoded):\n",
    "        if('from' in encoded):\n",
    "            decoded = {}\n",
    "            decoded['from'] = base64.standard_b64decode(encoded['from'])\n",
    "            decoded['data'] = base64.standard_b64decode(encoded['data']).decode('ascii')\n",
    "            decoded['seqno'] = base64.standard_b64decode(encoded['seqno'])\n",
    "            decoded['topicIDs'] = encoded['topicIDs']\n",
    "            decoded['encoded'] = encoded\n",
    "            return decoded\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def serialize_keras_model(self,model):\n",
    "        model.save('temp_model.h5')\n",
    "        f = open('temp_model.h5','rb')\n",
    "        model_bin = f.read()\n",
    "        f.close()\n",
    "        return model_bin\n",
    "    \n",
    "    def deserialize_keras_model(self,model_bin):\n",
    "        g = open('temp_model2.h5','wb')\n",
    "        g.write(model_bin)\n",
    "        g.close()\n",
    "        model = keras.models.load_model('temp_model2.h5')\n",
    "        return model\n",
    "    \n",
    "    def serialize_numpy(self, tensor):\n",
    "        return json.dumps(tensor.tolist()) # nested lists with same data, indices\n",
    "    \n",
    "    def deserialize_numpy(self,json_array):\n",
    "        return np.array(json.loads(json_array)).astype('float')\n",
    "    \n",
    "    def publish(self,channel,dict_message):\n",
    "        self.api.pubsub_pub(topic=channel,payload=json.dumps(dict_message))\n",
    "    \n",
    "    def generate_fit_spec(self, model,input,target,valid_input=None,valid_target=None,batch_size=1,epochs=1,log_interval=1):\n",
    "        \n",
    "        model_bin = self.serialize_keras_model(model)\n",
    "        model_addr = self.api.add_bytes(model_bin)\n",
    "\n",
    "        train_input = self.serialize_numpy(input)\n",
    "        train_target = self.serialize_numpy(target)\n",
    "\n",
    "        if(valid_input is None):\n",
    "            valid_input = self.serialize_numpy(input)\n",
    "        else:\n",
    "            valid_input = self.serialize_numpy(valid_input)\n",
    "\n",
    "        if(valid_target is None):\n",
    "            valid_target = self.serialize_numpy(target)\n",
    "        else:\n",
    "            valid_target = self.serialize_numpy(valid_target)\n",
    "\n",
    "        datasets = [train_input,train_target,valid_input,valid_target]\n",
    "        data_json = json.dumps(datasets)\n",
    "        data_addr = grid.api.add_str(data_json)\n",
    "\n",
    "        spec = {}\n",
    "        spec['model_addr'] = model_addr\n",
    "        spec['data_addr'] = data_addr\n",
    "        spec['batch_size'] = batch_size\n",
    "        spec['epochs'] = epochs\n",
    "        spec['log_interval'] = log_interval\n",
    "        spec['framework'] = 'keras'\n",
    "        spec['train_channel'] = 'openmined_train_'+str(model_addr)\n",
    "        return spec\n",
    "    \n",
    "    def listen_to_channel(self,handle_message,channel):\n",
    "        new_models = self.api.pubsub_sub(topic=channel,stream=True)\n",
    "\n",
    "\n",
    "        for m in new_models:\n",
    "            message = self.decode_message(m)\n",
    "            if(message is not None):\n",
    "                out = handle_message(message)\n",
    "                if(out is not None):\n",
    "                    return out\n",
    "                \n",
    "    def keras2ipfs(self,model):\n",
    "        return self.api.add_bytes(self.serialize_keras_model(model))\n",
    "    \n",
    "    def ipfs2keras(self,model_addr):\n",
    "        model_bin = self.api.cat(model_addr)\n",
    "        return self.deserialize_keras_model(model_bin)\n",
    "    \n",
    "    def receive_model(self,message, verbose=True):\n",
    "    \n",
    "        msg = json.loads(message['data'])\n",
    "        if(msg is not None):\n",
    "            if(msg['type'] == 'transact'):\n",
    "                return self.ipfs2keras(msg['model_addr']),msg\n",
    "            elif(msg['type'] == 'log'):\n",
    "                if(verbose):\n",
    "                    output = \"Worker:\" + msg['worker_id'][-5:]\n",
    "                    output += \" - Epoch \" + str(msg['epoch_id']) + \" of \" + str(msg['num_epochs'])\n",
    "                    output += \" - Valid Loss: \" + str(msg['eval_loss'])[0:8]\n",
    "                    print(output)\n",
    "    \n",
    "    def fit_worker(self,message):\n",
    "    \n",
    "        decoded = json.loads(message['data'])\n",
    "\n",
    "        if(decoded['framework'] == 'keras'):\n",
    "\n",
    "            model = self.ipfs2keras(decoded['model_addr'])\n",
    "\n",
    "            np_strings = json.loads(self.api.cat(decoded['data_addr']))\n",
    "            input,target,valid_input,valid_target = list(map(lambda x:self.deserialize_numpy(x),np_strings))\n",
    "            \n",
    "            for e in range(0,decoded['epochs'],decoded['log_interval']):\n",
    "                model.fit(input, target, batch_size=decoded['batch_size'], epochs=decoded['log_interval'], verbose=0)\n",
    "                eval_loss = model.evaluate(valid_input,valid_target,verbose=0)\n",
    "                spec = {}\n",
    "                spec['type'] = 'log'\n",
    "                spec['eval_loss'] = eval_loss\n",
    "                spec['epoch_id'] = e\n",
    "                spec['num_epochs'] = decoded['epochs']\n",
    "                spec['parent_model'] = decoded['model_addr']\n",
    "                spec['worker_id'] = self.id\n",
    "                self.publish(channel=decoded['train_channel'],dict_message=spec)\n",
    "\n",
    "            spec = {}\n",
    "            spec['type'] = 'transact'\n",
    "            spec['model_addr'] = self.keras2ipfs(model)\n",
    "            spec['eval_loss'] = eval_loss\n",
    "            spec['parent_model'] = decoded['model_addr']\n",
    "            spec['worker_id'] = self.id\n",
    "            self.publish(channel=decoded['train_channel'],dict_message=spec)\n",
    "\n",
    "            output = \"Model:\" + spec['parent_model'][-5:]\n",
    "            output += \" - Epochs \" + str(decoded['epochs'])\n",
    "            output += \" - Valid Loss: \" + str(spec['eval_loss'])[0:8]\n",
    "            print(output)\n",
    "\n",
    "            \n",
    "    def fit(self, model,input,target,valid_input=None,valid_target=None,batch_size=1,epochs=1,log_interval=1,message_handler=None):\n",
    "    \n",
    "        if(message_handler is None):\n",
    "            message_handler = self.receive_model\n",
    "        spec = self.generate_fit_spec(model,input,target,valid_input,valid_target,batch_size,epochs,log_interval)\n",
    "        self.publish('openmined_new_model',spec)\n",
    "        \n",
    "        trained = grid.listen_to_channel(message_handler,spec['train_channel'])\n",
    "        return trained\n",
    "    \n",
    "    def work(self):\n",
    "        grid.listen_to_channel(grid.fit_worker,'openmined_new_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = Grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id:b'\\x12 \\xaety\\x95\\xb0\\xeb\\xd2\\xb3f\\xc9\\xe1\\xa9\\x87\\xf8(\\xb0\\x98cm\\xa4\\xd3=\\xf3\\x9a\\xeax~\\xce\\x05mX['\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c0de783538e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mencoded\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'from'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/grid-0.1.0-py3.6.egg/grid/ipfsapi/http.py\u001b[0m in \u001b[0;36mstream_decode\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;31m# Decode each item as it is read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mstream_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \"\"\"\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/atrask/anaconda/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_message(decoded):\n",
    "    # send some sort of message\n",
    "    try:\n",
    "        # if message is a number... reply with the number + 1\n",
    "        api.pubsub_pub(topic='openmined_model_1',payload=int(decoded['data']) + 1)\n",
    "    except:\n",
    "        print(\"could not accumulate... message not an int\")\n",
    "    print(decoded['data'])\n",
    "\n",
    "# connect\n",
    "\n",
    "\n",
    "my_id = \"\"\n",
    "secret = random.randint(0,1000000)\n",
    "\n",
    "# send secret identity\n",
    "\n",
    "\n",
    "results = list()\n",
    "\n",
    "for encoded in g:\n",
    "    \n",
    "    if('from' in encoded):\n",
    "        # decode message\n",
    "        decoded = {}\n",
    "        decoded['from'] = base64.standard_b64decode(encoded['from'])\n",
    "        decoded['data'] = base64.standard_b64decode(encoded['data']).decode('ascii')\n",
    "        decoded['seqno'] = base64.standard_b64decode(encoded['seqno'])\n",
    "        decoded['topicIDs'] = encoded['topicIDs']\n",
    "        decoded['encoded'] = encoded\n",
    "        results.append(decoded)\n",
    "\n",
    "        # If I don't know who I am - wait for id\n",
    "        if(my_id == \"\"):\n",
    "            if(str(decoded['data'].split(\":\")[-1]) == str(secret)):\n",
    "                my_id = str(decoded['from'])\n",
    "                print(\"Id:\" + my_id)\n",
    "\n",
    "        # if I know who i am - process message\n",
    "        else:\n",
    "\n",
    "            if(str(decoded['from']) != my_id and decoded['data'][0:3] != 'id:'):\n",
    "                process_message(decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
