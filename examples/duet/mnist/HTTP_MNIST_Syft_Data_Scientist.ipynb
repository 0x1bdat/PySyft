{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Syft Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "# sy.LOG_FILE = \"syft_ds.log\"\n",
    "# _ = sy.logger.add(sy.LOG_FILE, enqueue=True, colorize=False, diagnose=True, backtrace=True, level=\"TRACE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Connect to a Remote Duet Server\n",
    "\n",
    "As the data scientist, you want to perform data science on data that is sitting in the Data Owner's Duet server (in their Notebook).\n",
    "\n",
    "In order to do this, we must run the code that the Data Owner sends us, which importantly includes their Duet Session ID. This will create a direct connection from my notebook to the remote Duet server. Once the connection is established all traffic is sent directly between the two nodes.\n",
    "\n",
    "Let's run the code below and follow the instructions it gives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id {\n",
      "  value: \"\\210^\\200\\234\\370\\031@q\\232\\352\\340\\\\\\225\\314@\\313\"\n",
      "}\n",
      "name: \"ucsf\"\n",
      "node {\n",
      "  id {\n",
      "    value: \"\\210^\\200\\234\\370\\031@q\\232\\352\\340\\\\\\225\\314@\\313\"\n",
      "  }\n",
      "  name: \"ucsf\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# #duet = sy.join_duet(network_url=\"http://localhost:5000\")\n",
    "# duet = sy.join_duet(network_url=\"http://localhost:5000\", loopback=True)\n",
    "\n",
    "from syft.grid.duet.om_signaling_client import register_http\n",
    "duet = register_http(url=\"http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Launch a Duet Server and Connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<syft.proxy.syft.lib.python.IntPointer object at 0x13b1d7f70>\n"
     ]
    }
   ],
   "source": [
    "x = duet.syft.lib.python.Int(1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-31 16:43:18.205 | CRITICAL | __main__:<module>:1 - Start requesting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 ms, sys: 3.52 ms, total: 23.6 ms\n",
      "Wall time: 51.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sy.logger.critical(\"Start requesting\")\n",
    "if len(duet.store) > 0:\n",
    "    t = duet.store[0].get(\n",
    "        request_block=True,\n",
    "        timeout_secs=15,\n",
    "        request_name=\"age_data\",\n",
    "        reason=\"I want to see the age data\",\n",
    "        delete_obj=False\n",
    "    )\n",
    "    sy.logger.critical(\"Finished requesting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get some references to our data owners Duet torch and torchvision\n",
    "torch = duet.torch\n",
    "torchvision = duet.torchvision\n",
    "\n",
    "# these are the same as the original mnist example\n",
    "transforms = torchvision.transforms\n",
    "datasets = torchvision.datasets\n",
    "nn = torch.nn\n",
    "F = torch.nn.functional\n",
    "optim = torch.optim\n",
    "StepLR = torch.optim.lr_scheduler.StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need some transforms for our MNIST data set\n",
    "local_transform_1 = tv.transforms.ToTensor()  # this converts PIL images to Tensors\n",
    "local_transform_2 = tv.transforms.Normalize(0.1307, 0.3081)  # this normalizes the dataset\n",
    "\n",
    "# compose our transforms\n",
    "local_transforms = tv.transforms.Compose([local_transform_1, local_transform_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings from original MNIST example command line args\n",
    "args = {\n",
    "    \"batch_size\": 32,\n",
    "    \"test_batch_size\": 1000,\n",
    "    \"epochs\": 14,\n",
    "    \"lr\": 1.0,\n",
    "    \"gamma\": 0.7,\n",
    "    \"no_cuda\": False,\n",
    "    \"dry_run\": False,\n",
    "    \"seed\": 42, # the meaning of life\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kwargs = {\n",
    "    \"batch_size\": args[\"test_batch_size\"],\n",
    "}\n",
    "\n",
    "# this is our carefully curated test data which represents the goal of our problem domain\n",
    "test_data = tv.datasets.MNIST('../data', train=False, download=True, transform=local_transforms)\n",
    "test_loader = th.utils.data.DataLoader(test_data,**test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "test_data_length = len(test_loader.dataset)\n",
    "print(test_data_length)\n",
    "\n",
    "# test_data_length_ptr = duet.syft.lib.python.Int(test_data_length)\n",
    "# print(test_data_length_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ../data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=0.1307, std=0.3081)\n",
      "           ) <class 'torchvision.datasets.mnist.MNIST'>\n"
     ]
    }
   ],
   "source": [
    "print(test_data, type(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"duet\" variable is now your reference to a whole world of remote operations including supported libraries like torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO replace with local inference so this doesn't need to be on the DO side\n",
    "# test_data_ptr = torchvision.datasets.MNIST('../data', train=False, download=True, transform=transforms)\n",
    "# print(test_data_ptr)\n",
    "\n",
    "# test_loader_ptr = torch.utils.data.DataLoader(test_data_ptr,**test_kwargs)\n",
    "# print(test_loader_ptr)\n",
    "# # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_model = nn.Sequential(\n",
    "#     nn.Conv2d(1, 32, 3, 1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(32, 64, 3, 1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2),\n",
    "#     nn.Dropout2d(0.25),\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(9216, 128),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout2d(0.5),\n",
    "#     nn.Linear(128, 10),\n",
    "#     nn.LogSoftmax(dim=1),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net:\n",
    "#     modules = []\n",
    "#     training = False\n",
    "\n",
    "#     def __init__(self) -> None:\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "#         self.dropout1 = nn.Dropout2d(0.25)\n",
    "#         self.dropout2 = nn.Dropout2d(0.5)\n",
    "#         self.fc1 = nn.Linear(9216, 128)\n",
    "#         self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "#         # add to modules list\n",
    "#         self.modules.append(self.conv1)\n",
    "#         self.modules.append(self.conv2)\n",
    "#         self.modules.append(self.dropout1)\n",
    "#         self.modules.append(self.dropout2)\n",
    "#         self.modules.append(self.fc1)\n",
    "#         self.modules.append(self.fc2)\n",
    "\n",
    "#     def train(self, mode: bool = True):\n",
    "#         self.training = mode\n",
    "#         for module in self.modules:\n",
    "#             module.train(mode)\n",
    "#         return self\n",
    "\n",
    "#     def eval(self):\n",
    "#         return self.train(False)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.max_pool2d(x, 2)\n",
    "#         x = self.dropout1(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.fc2(x)\n",
    "#         output = F.log_softmax(x, dim=1)\n",
    "#         return output\n",
    "\n",
    "#     def __call__(self, input):\n",
    "#         return self.forward(input)\n",
    "\n",
    "#     # local list of remote ListPointers of TensorPointers\n",
    "#     def parameters(self, recurse: bool = True):\n",
    "#         params_list = duet.syft.lib.python.List()\n",
    "#         for module in self.modules:\n",
    "#             param_pointers = module.parameters()\n",
    "#             params_list += param_pointers\n",
    "\n",
    "#         return params_list\n",
    "\n",
    "#     def cuda(self, device) -> \"Net\":\n",
    "#         for module in self.modules:\n",
    "#             module.cuda(device)\n",
    "#         return self\n",
    "\n",
    "#     def cpu(self) -> \"Net\":\n",
    "#         for module in self.modules:\n",
    "#             module.cpu()\n",
    "#         return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lets define our SOTA model to train on the data owners data\n",
    "# # note we subclass from sy.Module not nn.Module\n",
    "# fc1_scaling_factor = 0.25  # this can let us scale the fc1 layer down a bit\n",
    "# class SyNet(sy.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SyNet, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "#         self.conv2 = nn.Conv2d(32, int(64 * fc1_scaling_factor), 3, 1)  # keep fc1 size down\n",
    "#         self.dropout1 = nn.Dropout2d(0.25)\n",
    "#         self.dropout2 = nn.Dropout2d(0.5)\n",
    "#         self.fc1 = nn.Linear(int(9216 * fc1_scaling_factor), 128)\n",
    "#         self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.max_pool2d(x, 2)\n",
    "#         x = self.dropout1(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.fc2(x)\n",
    "#         output = F.log_softmax(x, dim=1)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lets define our SOTA model to train on the data owners data\n",
    "# # note we subclass from sy.Module not nn.Module\n",
    "# # WARNING: be extra careful to use th. not the torch from duet here\n",
    "# class LocalSyNet(sy.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LocalSyNet, self).__init__()\n",
    "#         self.conv1 = th.nn.Conv2d(1, 32, 3, 1)\n",
    "#         self.conv2 = th.nn.Conv2d(32, int(64 * fc1_scaling_factor), 3, 1)\n",
    "#         self.dropout1 = th.nn.Dropout2d(0.25)\n",
    "#         self.dropout2 = th.nn.Dropout2d(0.5)\n",
    "#         self.fc1 = th.nn.Linear(int(9216 * fc1_scaling_factor), 128)\n",
    "#         self.fc2 = th.nn.Linear(128, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = th.nn.functional.relu(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = th.nn.functional.relu(x)\n",
    "#         x = th.nn.functional.max_pool2d(x, 2)\n",
    "#         x = self.dropout1(x)\n",
    "#         x = th.flatten(x, 1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = th.nn.functional.relu(x)\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.fc2(x)\n",
    "#         output = th.nn.functional.log_softmax(x, dim=1)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallSyNet(sy.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallSyNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 392)\n",
    "        self.fc2 = nn.Linear(392, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalSmallSyNet(sy.Module):\n",
    "    def __init__(self):\n",
    "        super(LocalSmallSyNet, self).__init__()\n",
    "        self.fc1 = th.nn.Linear(784, 392)\n",
    "        self.fc2 = th.nn.Linear(392, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = th.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = th.nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# lets see if our Data Owner has CUDA\n",
    "has_cuda = False\n",
    "has_cuda_ptr = torch.cuda.is_available()\n",
    "has_cuda_ptr.request(request_name=\"cuda_is_available\", reason=\"To run test and inference locally\")\n",
    "has_cuda = bool(has_cuda_ptr.get(\n",
    "    request_block=False,\n",
    "    request_name=\"cuda_is_available\",\n",
    "    reason=\"To run test and inference locally\",\n",
    "    timeout_secs=3,  # change to something slower\n",
    "))\n",
    "# has_cuda = bool(has_cuda_ptr.get(\n",
    "#     request_block=True,\n",
    "#     request_name=\"cuda_is_available\",\n",
    "#     reason=\"To run test and inference locally\",\n",
    "#     timeout_secs=3,  # change to something slower\n",
    "# ))\n",
    "print(has_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO device is cpu\n"
     ]
    }
   ],
   "source": [
    "use_cuda = not args[\"no_cuda\"] and has_cuda\n",
    "torch.manual_seed(args[\"seed\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f\"DO device is {device.type.get()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate our model\n",
    "# this will construct everything inside init on the DO side\n",
    "# model = Net()\n",
    "# model = SyNet()\n",
    "# model = seq_model\n",
    "model = SmallSyNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "OrderedDict([('fc1', <syft.proxy.torch.nn.LinearPointer object at 0x13b1f9a60>), ('fc2', <syft.proxy.torch.nn.LinearPointer object at 0x10b8b4b50>)])\n"
     ]
    }
   ],
   "source": [
    "print(len(model.modules))\n",
    "print(model.modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Layer fc1 sum(weight): 0.0\n",
      "> Layer fc1 sum(bias): 0.0\n",
      "> Layer fc2 sum(weight): 0.0\n",
      "> Layer fc2 sum(bias): 0.0\n",
      "OrderedDict([('fc1', Linear(in_features=784, out_features=392, bias=True)), ('fc2', Linear(in_features=392, out_features=10, bias=True))])\n"
     ]
    }
   ],
   "source": [
    "# local_model = LocalSyNet()\n",
    "local_model = LocalSmallSyNet()\n",
    "local_model.zero_layers()  # so we can confirm that the weight download works\n",
    "local_model.sum_layers()\n",
    "print(local_model.modules)\n",
    "# assert local_model.fc1.in_features == int(9216 * fc1_scaling_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Downloading remote: fc1\n",
      ">> Setting weight copy on local fc1\n",
      ">> Setting bias copy on local fc1\n",
      "> Finished downloading model\n",
      "> Downloading remote: fc2\n",
      ">> Setting weight copy on local fc2\n",
      ">> Setting bias copy on local fc2\n",
      "> Finished downloading model\n"
     ]
    }
   ],
   "source": [
    "local_model.copy_remote_state(\n",
    "    remote_model=model,\n",
    "    request_name=\"model_download\",\n",
    "    reason=\"test evaluation\",\n",
    "    timeout_secs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "> Layer fc1 sum(weight): -1.5788923501968384\n",
      "> Layer fc1 sum(bias): 0.05938786640763283\n",
      "> Layer fc2 sum(weight): 0.4242194592952728\n",
      "> Layer fc2 sum(bias): -0.000538509339094162\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")\n",
    "local_model.sum_layers()\n",
    "# %%time\n",
    "# skip_layers = []\n",
    "# # warning fc1 is 9216x128 and stalls on copy, even a tensor size 9216x96 takes 45 seconds\n",
    "# # skip_layers.append(\"fc1\") # fc1 is too big???\n",
    "# # warning fc1 at 4608x128 takes about 25 seconds\n",
    "# local_model.copy_remote_state(remote_model=model, skip_layers=skip_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check the weights were copied\n",
    "# local_model.sum_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have CUDA lets send our model to the GPU\n",
    "if has_cuda:\n",
    "    model.cuda(device)\n",
    "else:\n",
    "    model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<syft.proxy.syft.lib.python.ListPointer object at 0x13b25a1c0> <class 'syft.proxy.syft.lib.python.ListPointer'>\n"
     ]
    }
   ],
   "source": [
    "# lets get our parameters for optimization\n",
    "# params_list required for remote list concatenation\n",
    "params = model.parameters(params_list=duet.syft.lib.python.List())\n",
    "print(params, type(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<syft.proxy.torch.optim.AdadeltaPointer object at 0x13bbb2e20> <class 'syft.proxy.torch.optim.AdadeltaPointer'>\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adadelta(params, lr=args[\"lr\"])\n",
    "print(optimizer, type(optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<syft.proxy.torch.optim.lr_scheduler.StepLRPointer object at 0x13b25a2b0> <class 'syft.proxy.torch.optim.lr_scheduler.StepLRPointer'>\n"
     ]
    }
   ],
   "source": [
    "scheduler = StepLR(optimizer, step_size=1, gamma=args[\"gamma\"])\n",
    "print(scheduler, type(scheduler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now can define a simple training loop very similar to the original PyTorch MNIST example\n",
    "@sy.logger.catch\n",
    "def train(args, model, device, train_loader, optimizer, epoch, train_data_length):\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    train_batches = round((train_data_length / args[\"batch_size\"]) + 0.5)\n",
    "    print(f\"> Running train in {train_batches} batches\")\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "#         time.sleep(1)\n",
    "        data_ptr, target_ptr = data[0], data[1]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data_ptr)\n",
    "        loss = F.nll_loss(output, target_ptr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_item = loss.item()\n",
    "        train_loss = duet.syft.lib.python.Float(0)\n",
    "        train_loss += loss_item\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "#             local_loss = loss_item.get(\n",
    "#                 request_name=\"loss\",\n",
    "#                 reason=\"To evaluate training progress\",\n",
    "#                 request_block=True,\n",
    "#                 timeout_secs=5\n",
    "#             )\n",
    "            local_loss = None\n",
    "            if local_loss is not None:\n",
    "                print(\"Train Epoch: {} {} {:.4}\".format(epoch, batch_idx, local_loss))\n",
    "            else:\n",
    "                print(\"Train Epoch: {} {} ?\".format(epoch, batch_idx))\n",
    "            if args[\"dry_run\"]:\n",
    "                break\n",
    "        if batch_idx >= train_batches - 1:\n",
    "            print(\"batch_idx >= train_batches, breaking\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO replace with local inference and local test set\n",
    "# # the same for our test training loop except we will need to send our data over for inference\n",
    "# def test(model, device, test_loader, test_data_length):\n",
    "#     # + 0.5 lets us math.ceil without the import\n",
    "#     test_batches = round((test_data_length / args[\"test_batch_size\"]) + 0.5)\n",
    "#     print(f\"> Running test in {test_batches} batches\")\n",
    "#     model.eval()\n",
    "#     test_loss = duet.syft.lib.python.Float(0)\n",
    "#     correct_ptr = duet.syft.lib.python.Float(0)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx, data in enumerate(test_loader):\n",
    "#             data_ptr, target_ptr = data[0], data[1]\n",
    "#             output = model(data_ptr)\n",
    "#             loss = F.nll_loss(output, target_ptr, reduction='sum').item()\n",
    "#             test_loss = test_loss + loss\n",
    "\n",
    "#             pred = output.argmax(dim=1)\n",
    "#             total = pred.eq(target_ptr).sum().item()\n",
    "#             correct_ptr += total\n",
    "\n",
    "#             if args[\"dry_run\"]:\n",
    "#                 break\n",
    "                \n",
    "#             if batch_idx >= test_batches - 1:\n",
    "#                 print(\"batch_idx >= test_batches, breaking\")\n",
    "#                 break\n",
    "\n",
    "#     accuracy = correct_ptr / test_data_length\n",
    "#     # we need to batch or block these requests so the loop doesnt break\n",
    "#     result = None\n",
    "# #     result = accuracy.get(\n",
    "# #         request_block=True,\n",
    "# #         timeout_secs=0,\n",
    "# #         request_name=\"accuracy\",\n",
    "# #         reason=\"To see the accuracy on DO's test set\"\n",
    "# #     )\n",
    "#     if result is not None:\n",
    "#         print(\"Test Set Average Loss:\", 100 * result)\n",
    "#     else:\n",
    "#         print(\"Test Set Average Loss: ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO replace with local inference and local test set\n",
    "# the same for our test training loop except we will need to send our data over for inference\n",
    "@sy.logger.catch\n",
    "def test_local(model, remote_model, test_loader, test_data_length):\n",
    "    # download remote model\n",
    "    model.copy_remote_state(\n",
    "        remote_model=remote_model,\n",
    "        request_name=\"model_download\",\n",
    "        reason=\"test evaluation\",\n",
    "        timeout_secs=30\n",
    "    )\n",
    "    # visually check the weights have changed\n",
    "    model.sum_layers()\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    test_batches = round((test_data_length / args[\"test_batch_size\"]) + 0.5)\n",
    "    print(f\"> Running test_local in {test_batches} batches\")\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    with th.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "#             time.sleep(1)\n",
    "            output = model(data)\n",
    "            iter_loss = th.nn.functional.nll_loss(output, target, reduction='sum').item()\n",
    "            test_loss = test_loss + iter_loss\n",
    "            pred = output.argmax(dim=1)\n",
    "            total = pred.eq(target).sum().item()\n",
    "            correct += total\n",
    "            if args[\"dry_run\"]:\n",
    "                break\n",
    "                \n",
    "            if batch_idx >= test_batches - 1:\n",
    "                print(\"batch_idx >= test_batches, breaking\")\n",
    "                break\n",
    "\n",
    "    accuracy = correct / test_data_length\n",
    "    print(\"Test Set Average Loss:\", 100 * accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'syft.proxy.torchvision.transforms.ToTensorPointer'> <class 'syft.proxy.torchvision.transforms.NormalizePointer'>\n",
      "<syft.proxy.torchvision.datasets.MNISTPointer object at 0x13b25a0a0>\n",
      "<syft.proxy.torch.utils.data.DataLoaderPointer object at 0x13bc35250>\n"
     ]
    }
   ],
   "source": [
    "# we need some transforms for our MNIST data set\n",
    "transform_1 = torchvision.transforms.ToTensor()  # this converts PIL images to Tensors\n",
    "transform_2 = torchvision.transforms.Normalize(0.1307, 0.3081)  # this normalizes the dataset\n",
    "print(type(transform_1), type(transform_2))\n",
    "\n",
    "remote_list = duet.syft.lib.python.List()\n",
    "remote_list.append(transform_1)\n",
    "remote_list.append(transform_2)\n",
    "\n",
    "# compose our transforms\n",
    "transforms = torchvision.transforms.Compose(remote_list)\n",
    "\n",
    "# The DO has kindly let us initialise a DataLoader for their training set\n",
    "train_kwargs = {\n",
    "    \"batch_size\": args[\"batch_size\"],\n",
    "}\n",
    "train_data_ptr = torchvision.datasets.MNIST('../data', train=True, download=True, transform=transforms)\n",
    "print(train_data_ptr)\n",
    "train_loader_ptr = torch.utils.data.DataLoader(train_data_ptr,**train_kwargs)\n",
    "print(train_loader_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset size is: 60000\n"
     ]
    }
   ],
   "source": [
    "train_data_length = 60000\n",
    "def get_train_length(train_data_ptr):\n",
    "    train_length_ptr = train_data_ptr.__len__()\n",
    "    train_data_length = train_length_ptr.request(\n",
    "        request_name=\"train_size\",\n",
    "        reason=\"To write the training loop\",\n",
    "    )\n",
    "    train_length_ptr.get(delete_obj=False)\n",
    "    return train_data_length\n",
    "\n",
    "try:\n",
    "    if train_data_length is None:\n",
    "        train_data_length = get_train_length(train_data_ptr)\n",
    "except NameError:\n",
    "        train_data_length = get_train_length(train_data_ptr)\n",
    "\n",
    "print(f\"Training Dataset size is: {train_data_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "> Running train in 1876 batches\n",
      "Train Epoch: 1 0 ?\n",
      "Train Epoch: 1 10 ?\n",
      "Train Epoch: 1 20 ?\n",
      "Train Epoch: 1 30 ?\n",
      "Train Epoch: 1 40 ?\n",
      "Train Epoch: 1 50 ?\n",
      "Train Epoch: 1 60 ?\n",
      "Train Epoch: 1 70 ?\n",
      "Train Epoch: 1 80 ?\n",
      "Train Epoch: 1 90 ?\n",
      "Train Epoch: 1 100 ?\n",
      "Train Epoch: 1 110 ?\n",
      "Train Epoch: 1 120 ?\n",
      "Train Epoch: 1 130 ?\n",
      "Train Epoch: 1 140 ?\n",
      "Train Epoch: 1 150 ?\n",
      "Train Epoch: 1 160 ?\n",
      "Train Epoch: 1 170 ?\n",
      "Train Epoch: 1 180 ?\n",
      "Train Epoch: 1 190 ?\n",
      "Train Epoch: 1 200 ?\n",
      "Train Epoch: 1 210 ?\n",
      "Train Epoch: 1 220 ?\n",
      "Train Epoch: 1 230 ?\n",
      "Train Epoch: 1 240 ?\n",
      "Train Epoch: 1 250 ?\n",
      "Train Epoch: 1 260 ?\n",
      "Train Epoch: 1 270 ?\n",
      "Train Epoch: 1 280 ?\n",
      "Train Epoch: 1 290 ?\n",
      "Train Epoch: 1 300 ?\n",
      "Train Epoch: 1 310 ?\n",
      "Train Epoch: 1 320 ?\n",
      "Train Epoch: 1 330 ?\n",
      "Train Epoch: 1 340 ?\n",
      "Train Epoch: 1 350 ?\n",
      "Train Epoch: 1 360 ?\n",
      "Train Epoch: 1 370 ?\n",
      "Train Epoch: 1 380 ?\n",
      "Train Epoch: 1 390 ?\n",
      "Train Epoch: 1 400 ?\n",
      "Train Epoch: 1 410 ?\n",
      "Train Epoch: 1 420 ?\n",
      "Train Epoch: 1 430 ?\n",
      "Train Epoch: 1 440 ?\n",
      "Train Epoch: 1 450 ?\n",
      "Train Epoch: 1 460 ?\n",
      "Train Epoch: 1 470 ?\n",
      "Train Epoch: 1 480 ?\n",
      "Train Epoch: 1 490 ?\n",
      "Train Epoch: 1 500 ?\n",
      "Train Epoch: 1 510 ?\n",
      "Train Epoch: 1 520 ?\n",
      "Train Epoch: 1 530 ?\n",
      "Train Epoch: 1 540 ?\n",
      "Train Epoch: 1 550 ?\n",
      "Train Epoch: 1 560 ?\n",
      "Train Epoch: 1 570 ?\n",
      "Train Epoch: 1 580 ?\n",
      "Train Epoch: 1 590 ?\n",
      "Train Epoch: 1 600 ?\n",
      "Train Epoch: 1 610 ?\n",
      "Train Epoch: 1 620 ?\n",
      "Train Epoch: 1 630 ?\n",
      "Train Epoch: 1 640 ?\n",
      "Train Epoch: 1 650 ?\n",
      "Train Epoch: 1 660 ?\n",
      "Train Epoch: 1 670 ?\n",
      "Train Epoch: 1 680 ?\n",
      "Train Epoch: 1 690 ?\n",
      "Train Epoch: 1 700 ?\n",
      "Train Epoch: 1 710 ?\n",
      "Train Epoch: 1 720 ?\n",
      "Train Epoch: 1 730 ?\n",
      "Train Epoch: 1 740 ?\n",
      "Train Epoch: 1 750 ?\n",
      "Train Epoch: 1 760 ?\n",
      "Train Epoch: 1 770 ?\n",
      "Train Epoch: 1 780 ?\n",
      "Train Epoch: 1 790 ?\n",
      "Train Epoch: 1 800 ?\n",
      "Train Epoch: 1 810 ?\n",
      "Train Epoch: 1 820 ?\n",
      "Train Epoch: 1 830 ?\n",
      "Train Epoch: 1 840 ?\n",
      "Train Epoch: 1 850 ?\n",
      "Train Epoch: 1 860 ?\n",
      "Train Epoch: 1 870 ?\n",
      "Train Epoch: 1 880 ?\n",
      "Train Epoch: 1 890 ?\n",
      "Train Epoch: 1 900 ?\n",
      "Train Epoch: 1 910 ?\n",
      "Train Epoch: 1 920 ?\n",
      "Train Epoch: 1 930 ?\n",
      "Train Epoch: 1 940 ?\n",
      "Train Epoch: 1 950 ?\n",
      "Train Epoch: 1 960 ?\n",
      "Train Epoch: 1 970 ?\n",
      "Train Epoch: 1 980 ?\n",
      "Train Epoch: 1 990 ?\n",
      "Train Epoch: 1 1000 ?\n",
      "Train Epoch: 1 1010 ?\n",
      "Train Epoch: 1 1020 ?\n",
      "Train Epoch: 1 1030 ?\n",
      "Train Epoch: 1 1040 ?\n",
      "Train Epoch: 1 1050 ?\n",
      "Train Epoch: 1 1060 ?\n",
      "Train Epoch: 1 1070 ?\n",
      "Train Epoch: 1 1080 ?\n",
      "Train Epoch: 1 1090 ?\n",
      "Train Epoch: 1 1100 ?\n",
      "Train Epoch: 1 1110 ?\n",
      "Train Epoch: 1 1120 ?\n",
      "Train Epoch: 1 1130 ?\n",
      "Train Epoch: 1 1140 ?\n",
      "Train Epoch: 1 1150 ?\n",
      "Train Epoch: 1 1160 ?\n",
      "Train Epoch: 1 1170 ?\n",
      "Train Epoch: 1 1180 ?\n",
      "Train Epoch: 1 1190 ?\n",
      "Train Epoch: 1 1200 ?\n",
      "Train Epoch: 1 1210 ?\n",
      "Train Epoch: 1 1220 ?\n",
      "Train Epoch: 1 1230 ?\n",
      "Train Epoch: 1 1240 ?\n",
      "Train Epoch: 1 1250 ?\n",
      "Train Epoch: 1 1260 ?\n",
      "Train Epoch: 1 1270 ?\n",
      "Train Epoch: 1 1280 ?\n",
      "Train Epoch: 1 1290 ?\n",
      "Train Epoch: 1 1300 ?\n",
      "Train Epoch: 1 1310 ?\n",
      "Train Epoch: 1 1320 ?\n",
      "Train Epoch: 1 1330 ?\n",
      "Train Epoch: 1 1340 ?\n",
      "Train Epoch: 1 1350 ?\n",
      "Train Epoch: 1 1360 ?\n",
      "Train Epoch: 1 1370 ?\n",
      "Train Epoch: 1 1380 ?\n",
      "Train Epoch: 1 1390 ?\n",
      "Train Epoch: 1 1400 ?\n",
      "Train Epoch: 1 1410 ?\n",
      "Train Epoch: 1 1420 ?\n",
      "Train Epoch: 1 1430 ?\n",
      "Train Epoch: 1 1440 ?\n",
      "Train Epoch: 1 1450 ?\n",
      "Train Epoch: 1 1460 ?\n",
      "Train Epoch: 1 1470 ?\n",
      "Train Epoch: 1 1480 ?\n",
      "Train Epoch: 1 1490 ?\n",
      "Train Epoch: 1 1500 ?\n",
      "Train Epoch: 1 1510 ?\n",
      "Train Epoch: 1 1520 ?\n",
      "Train Epoch: 1 1530 ?\n",
      "Train Epoch: 1 1540 ?\n",
      "Train Epoch: 1 1550 ?\n",
      "Train Epoch: 1 1560 ?\n",
      "Train Epoch: 1 1570 ?\n",
      "Train Epoch: 1 1580 ?\n",
      "Train Epoch: 1 1590 ?\n",
      "Train Epoch: 1 1600 ?\n",
      "Train Epoch: 1 1610 ?\n",
      "Train Epoch: 1 1620 ?\n",
      "Train Epoch: 1 1630 ?\n",
      "Train Epoch: 1 1640 ?\n",
      "Train Epoch: 1 1650 ?\n",
      "Train Epoch: 1 1660 ?\n",
      "Train Epoch: 1 1670 ?\n",
      "Train Epoch: 1 1680 ?\n",
      "Train Epoch: 1 1690 ?\n",
      "Train Epoch: 1 1700 ?\n",
      "Train Epoch: 1 1710 ?\n",
      "Train Epoch: 1 1720 ?\n",
      "Train Epoch: 1 1730 ?\n",
      "Train Epoch: 1 1740 ?\n",
      "Train Epoch: 1 1750 ?\n",
      "Train Epoch: 1 1760 ?\n",
      "Train Epoch: 1 1770 ?\n",
      "Train Epoch: 1 1780 ?\n",
      "Train Epoch: 1 1790 ?\n",
      "Train Epoch: 1 1800 ?\n",
      "Train Epoch: 1 1810 ?\n",
      "Train Epoch: 1 1820 ?\n",
      "Train Epoch: 1 1830 ?\n",
      "Train Epoch: 1 1840 ?\n",
      "Train Epoch: 1 1850 ?\n",
      "Train Epoch: 1 1860 ?\n",
      "Train Epoch: 1 1870 ?\n",
      "batch_idx >= train_batches, breaking\n",
      "> Downloading remote: fc1\n",
      ">> Setting weight copy on local fc1\n",
      ">> Setting bias copy on local fc1\n",
      "> Finished downloading model\n",
      "> Downloading remote: fc2\n",
      ">> Setting weight copy on local fc2\n",
      ">> Setting bias copy on local fc2\n",
      "> Finished downloading model\n",
      "> Layer fc1 sum(weight): -7193741312.0\n",
      "> Layer fc1 sum(bias): 29403728.0\n",
      "> Layer fc2 sum(weight): 15277283.0\n",
      "> Layer fc2 sum(bias): 45.15621566772461\n",
      "> Running test_local in 10 batches\n",
      "batch_idx >= test_batches, breaking\n",
      "Test Set Average Loss: 11.35\n",
      "Epoch time: 896 seconds\n",
      "CPU times: user 4min 46s, sys: 24.3 s, total: 5min 10s\n",
      "Wall time: 14min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "# sequential CPU times: user 39.2 s, sys: 390 ms, total: 39.6s per epoch\n",
    "# sy.module CPU times: user 1min 28s, sys: 645 ms, total: 1min 28s per epoch\n",
    "# vanilla class CPU times: user 3min 5s, sys: 3.01 s, total: 3min 8s per epoch\n",
    "\n",
    "args[\"dry_run\"] = False\n",
    "sy.logger.trace(\"Start Training\")\n",
    "for epoch in range(1, args[\"epochs\"] + 1):\n",
    "    epoch_start = time.time()\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    train(args, model, device, train_loader_ptr, optimizer, epoch, train_data_length)\n",
    "    #test(model, device, test_loader_ptr, test_data_length_ptr)\n",
    "    test_local(local_model, model, test_loader, test_data_length)  # real local data and model\n",
    "    scheduler.step()\n",
    "    epoch_end = time.time()\n",
    "    print(f\"Epoch time: {int(epoch_end - epoch_start)} seconds\")\n",
    "    break\n",
    "sy.logger.trace(\"Finish Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3: Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def draw_image_and_label(image, label):\n",
    "    fig = plt.figure()\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"none\")\n",
    "    plt.title(\"Ground Truth: {}\".format(label))\n",
    "    \n",
    "def prep_for_inference(image):\n",
    "    image_batch = image.unsqueeze(0).unsqueeze(0)\n",
    "    image_batch = image_batch * 1.0\n",
    "    return image_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_local(image):\n",
    "    image_tensor = th.Tensor(prep_for_inference(image))\n",
    "    print(\"1\", type(image_tensor))\n",
    "    output = local_model(image_tensor)\n",
    "    print(\"2\", type(output))\n",
    "    preds = th.exp(output)\n",
    "    print(\"3\", type(preds))\n",
    "    local_y = preds\n",
    "    local_y = local_y.squeeze()\n",
    "    pos = local_y == max(local_y)\n",
    "    index = th.nonzero(pos, as_tuple=False)\n",
    "    class_num = index.squeeze()\n",
    "    return class_num, local_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(image):\n",
    "    image_tensor_ptr = torch.Tensor(prep_for_inference(image))\n",
    "    output = model(image_tensor_ptr)\n",
    "    preds = torch.exp(output)\n",
    "    preds_result = preds.get(\n",
    "        request_block=True,\n",
    "        request_name=\"inference\",\n",
    "        reason=\"To see a real world example of inference\",\n",
    "        timeout_secs=10\n",
    "    )\n",
    "    if preds_result is None:\n",
    "        print(\"No permission to do inference, request again\")\n",
    "        return -1, th.Tensor([-1])\n",
    "    else:\n",
    "        local_y = th.Tensor(preds_result)\n",
    "        local_y = local_y.squeeze()\n",
    "        pos = local_y == max(local_y)\n",
    "        index = th.nonzero(pos, as_tuple=False)\n",
    "        class_num = index.squeeze()\n",
    "        return class_num, local_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Test Image: 3467\n",
      "Displaying 3467 == 467 in Batch: 3/10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets grab something from the test set\n",
    "import random\n",
    "total_images = test_data_length # 10000\n",
    "index = random.randint(0, total_images)\n",
    "print(\"Random Test Image:\", index)\n",
    "count = 0\n",
    "batch = index // test_kwargs[\"batch_size\"]\n",
    "batch_index = index % int(total_images / len(test_loader))\n",
    "for tensor_ptr in test_loader:\n",
    "    data, target = tensor_ptr[0], tensor_ptr[1]\n",
    "    if batch == count:\n",
    "        break\n",
    "    count += 1\n",
    "\n",
    "print(f\"Displaying {index} == {batch_index} in Batch: {batch}/{len(test_loader)}\")\n",
    "image_1 = data[batch_index].reshape((28, 28))\n",
    "label_1 = target[batch_index]\n",
    "draw_image_and_label(image_1, label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classify remote\n",
    "# sy.logger.trace(\"Before running classify\")\n",
    "# class_num, preds = classify(image_1)\n",
    "# print(f\"Prediction: {class_num} Ground Truth: {label_1}\")\n",
    "# print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 <class 'torch.Tensor'>\n",
      "2 <class 'torch.Tensor'>\n",
      "3 <class 'torch.Tensor'>\n",
      "Prediction: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) Ground Truth: 9\n",
      "tensor([inf, inf, inf, inf, inf, inf, inf, inf, inf, inf],\n",
      "       grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# classify local\n",
    "sy.logger.trace(\"Before running classify\")\n",
    "class_num, preds = classify_local(image_1)\n",
    "print(f\"Prediction: {class_num} Ground Truth: {label_1}\")\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error with recv_immediate_msg_with_reply. 'generator' object has no attribute 'serialize'\n",
    "# remote_model_params_ptr = model.parameters()\n",
    "# remote_model_params = remote_model_params_ptr.get(\n",
    "#     request_block=True,\n",
    "#     request_name=\"copy_model\",\n",
    "#     reason=\"To run test and inference locally\",\n",
    "#     timeout_secs=10,\n",
    "#     delete_obj=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(remote_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
