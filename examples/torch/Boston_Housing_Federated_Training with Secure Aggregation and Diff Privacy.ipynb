{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ALSfsSFjeV1o"
   },
   "source": [
    "# Federated Learning with Secure Aggregation and Diff Privacy using PySyft\n",
    "\n",
    "This is an example of using our new Secure Multi-Party Computation tensor (SPDZTensor) to perform an encrypted average of gradients across multiple data owners.\n",
    "\n",
    "Before starting with this notebook, we recommend looking at `Boston_Housing_Federated_Training.ipynb` which is located in the same folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nFvJUEHOfA-r"
   },
   "source": [
    "# Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From https://github.com/LaRiffle/differential-privacy\n",
      " * branch            HEAD       -> FETCH_HEAD\n",
      "Already up to date.\n",
      "Collecting websockets\n",
      "  Using cached https://files.pythonhosted.org/packages/0f/d9/e04264525261f352c6d9070f2f69fb83c5df6954aa5c1697b28732a12481/websockets-6.0-cp36-cp36m-macosx_10_6_intel.whl\n",
      "\u001b[31mmkl-random 1.0.1 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[31mmkl-fft 1.0.4 requires cython, which is not installed.\u001b[0m\n",
      "\u001b[31mtensorflow 1.9.0 has requirement setuptools<=39.1.0, but you'll have setuptools 40.0.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: websockets\n",
      "  Found existing installation: websockets 6.0\n",
      "    Uninstalling websockets-6.0:\n",
      "      Successfully uninstalled websockets-6.0\n",
      "Successfully installed websockets-6.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! URL=\"https://github.com/LaRiffle/differential-privacy.git\" && FOLDER=\"differential_privacy\" && if [ ! -d $FOLDER ]; then git clone $URL $FOLDER; else (cd $FOLDER && git pull $URL && cd ..); fi;\n",
    "! pip install --upgrade --force-reinstall websockets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1.post2\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch Example')\n",
    "parser.add_argument('--batch-size', type=int, default=8, metavar='N',\n",
    "                    help='input batch size for training (default: 8)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=8, metavar='N',\n",
    "                    help='input batch size for testing (default: 8)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
    "                    help='learning rate (default: 0.001)')\n",
    "parser.add_argument('--momentum', type=float, default=0.0, metavar='M',\n",
    "                    help='SGD momentum (default: 0.0)')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "args = parser.parse_args([])\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "kwargs ={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "caoZ_dM0wzdf",
    "outputId": "1a138f2e-f184-4b94-a93b-486617bde21a"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open('../other/data/boston_housing.pickle','rb')\n",
    "((X, y), (X_test, y_test)) = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "X = torch.from_numpy(X).type(torch.FloatTensor)\n",
    "y = torch.from_numpy(y).type(torch.FloatTensor)\n",
    "X_test = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.FloatTensor)\n",
    "# preprocessing\n",
    "mean = X.mean(0, keepdim=True)\n",
    "dev = X.std(0, keepdim=True)\n",
    "mean[:, 3] = 0. # the feature at column 3 is binary,\n",
    "dev[:, 3] = 1.  # so I'd rather not standardize it\n",
    "X = (X - mean) / dev\n",
    "X_test = (X_test - mean) / dev\n",
    "train = TensorDataset(X, y)\n",
    "test = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train, batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "test_loader = DataLoader(test, batch_size=args.test_batch_size, shuffle=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Az9PH1BrfK46"
   },
   "source": [
    "#  Neural Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R5TyXfcOXp1w"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, 32)\n",
    "        self.fc2 = nn.Linear(32, 24)\n",
    "        self.fc3 = nn.Linear(24, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 13)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def divide_clip_grads(self):\n",
    "        for key, param in self.named_parameters():\n",
    "            param.grad /= n_batch\n",
    "            gradient_clip(param)\n",
    "            \n",
    "    def add_noise_to_grads(self):\n",
    "        for key, param in self.named_parameters():\n",
    "            noise = 1/LOT_SIZE * gaussian_noise(param.grad)\n",
    "            param.grad += noise\n",
    "model = Net()\n",
    "model_params = list(model.parameters())\n",
    "\n",
    "bobs_model = Net()\n",
    "alices_model = Net()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8r78FvSffTp0"
   },
   "source": [
    "# Hooking into Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ai5bqlEWSFgf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Worker bob already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker alice already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 0 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 0 already exists. Replacing old worker which could cause unexpected behavior\n"
     ]
    }
   ],
   "source": [
    "import syft\n",
    "import syft as sy\n",
    "from syft.core import utils\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import random\n",
    "from syft.core.frameworks.torch import utils as torch_utils\n",
    "from torch.autograd import Variable\n",
    "hook = sy.TorchHook(verbose=False)\n",
    "me = hook.local_worker\n",
    "bob = sy.VirtualWorker(id=\"bob\",hook=hook, is_client_worker=False)\n",
    "alice = sy.VirtualWorker(id=\"alice\",hook=hook, is_client_worker=False)\n",
    "me.is_client_worker = False\n",
    "\n",
    "compute_nodes = [bob, alice]\n",
    "\n",
    "me.add_workers([bob, alice])\n",
    "bob.add_workers([me, alice])\n",
    "alice.add_workers([me, bob])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "apSGFY_fv_7z"
   },
   "source": [
    "**Send data to the worker** <br>\n",
    "Usually they would already have it, this is just for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UByFBzz2wARz"
   },
   "outputs": [],
   "source": [
    "remote_dataset = (list(),list())\n",
    "\n",
    "for batch_idx, (data,target) in enumerate(train_loader):\n",
    "    data = Variable(data)\n",
    "    target = Variable(target.float())\n",
    "    data.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
    "    target.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
    "    remote_dataset[batch_idx % len(compute_nodes)].append((data, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma = 9.689610525210778\n",
      "The mechanism is (O(0.297030), 0.000010)-differentially private\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Inspired from Abadi et al., Deep Learning with Differential Privacy, \n",
    "    Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications\n",
    "    Security, 2016\n",
    "\"\"\"\n",
    "from differential_privacy.privacy_accountant.pytorch import accountant\n",
    "import numpy as np\n",
    "\n",
    "n_batch = 3\n",
    "NUM_TRAINING_IMAGES = X.size()[0]\n",
    "LOT_SIZE = n_batch * args.batch_size\n",
    "N_LOTS = 100\n",
    "T = N_LOTS # number of samplings\n",
    "\n",
    "bound = 10\n",
    "epsilon = 0.5\n",
    "delta = 10**(-5)\n",
    "sigma = np.sqrt(2 * np.log(1.25/delta))/epsilon \n",
    "\n",
    "def sum_batch(grads):\n",
    "    n_items = len(grads)\n",
    "    return grads.view(n_items, -1).sum(dim=1)\n",
    "\n",
    "def gradient_clip(param):\n",
    "    \"\"\"Clip gradient to ensure ||param.grad||2 < bound\"\"\"\n",
    "    nn.utils.clip_grad_norm([param], bound)\n",
    "\n",
    "def gaussian_noise(grads):\n",
    "    \"\"\"Add gaussian noise to gradients\"\"\"\n",
    "    shape = grads.shape\n",
    "    noise = Variable(torch.zeros(shape))\n",
    "    noise.data.normal_(0.0, std=bound*sigma)\n",
    "    return noise\n",
    "\n",
    "q = LOT_SIZE / NUM_TRAINING_IMAGES\n",
    "spent_epsilon = q * epsilon * np.sqrt(T)\n",
    "spent_delta = delta\n",
    "print('sigma =', sigma)\n",
    "print('The mechanism is (O(%f), %f)-differentially private' % (spent_epsilon, spent_delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diff Privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_accountant = accountant.GaussianMomentsAccountant(NUM_TRAINING_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def select_lot(worker_dataset):    # given a worker_dataset\n",
    "    \"\"\"\n",
    "    Build the lot by sampling over the dataset\n",
    "    \"\"\"\n",
    "    #- select indices in worker_dataset of tensors \n",
    "    valid_ids = np.arange(len(worker_dataset)-1) \n",
    "    #- Select indices and reshape into batches\n",
    "    batches_ids = np.random.choice(valid_ids,size=LOT_SIZE, replace=False).reshape(-1, args.batch_size)\n",
    "    #- Build lot\n",
    "    lot = []\n",
    "    for batch_ids in batches_ids:\n",
    "        batch_data = []\n",
    "        batch_target = []\n",
    "        print(batch_ids)\n",
    "        for batch_id in batch_ids:\n",
    "            data, target = worker_dataset[batch_id]\n",
    "            batch_data.append(data)\n",
    "            batch_target.append(target)\n",
    "        \n",
    "        lot.append((torch.stack(batch_data), torch.stack(batch_target)))     \n",
    "    return lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(worker_dataset, model, optimizer, lot_idx):\n",
    "    # Build the lot by sampling over the dataset\n",
    "    lot = select_lot(worker_dataset)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "    # Iterate on the lot batch per batch\n",
    "    for batch_idx, (data,target) in enumerate(lot):\n",
    "        \n",
    "        # update the model\n",
    "        model.send(data.location)\n",
    "\n",
    "        pred = model(data)\n",
    "        loss = F.mse_loss(pred, target.float())\n",
    "        # Note that because we apply backward() several times without resetting \n",
    "        # the grads (optimizer.zero_grad()), we sum the gradients \n",
    "        loss.backward() \n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            loss.get()\n",
    "            print('Train Lot: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                lot_idx, batch_idx * args.batch_size, LOT_SIZE,\n",
    "                100. * batch_idx * args.batch_size / LOT_SIZE, loss.data[0]))\n",
    "            print(priv_accountant.get_privacy_spent(target_deltas=[spent_delta]))\n",
    "       \n",
    "\n",
    "    \n",
    "    optimizer.step()\n",
    "        \n",
    "    priv_accountant.accumulate_privacy_spending(bound * sigma, LOT_SIZE)\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_optimizer = optim.SGD(bobs_model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "alices_optimizer = optim.SGD(alices_model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "models = [bobs_model, alices_model]\n",
    "params = [list(bobs_model.parameters()), list(alices_model.parameters())]\n",
    "optimizers = [bobs_optimizer, alices_optimizer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Federated Learning training\n",
    "def train(lot_idx):        \n",
    "    # update remote models\n",
    "    for remote_index in range(len(compute_nodes)):\n",
    "        models[remote_index].train()\n",
    "        worker_dataset = remote_dataset[remote_index]\n",
    "        models[remote_index] = update(worker_dataset, models[remote_index], optimizers[remote_index], lot_idx)\n",
    "\n",
    "    new_params = list()\n",
    "\n",
    "    for param_i in range(len(params[0])):\n",
    "\n",
    "        spdz_params = list()\n",
    "        for remote_index in range(len(compute_nodes)):\n",
    "            spdz_params.append((params[remote_index][param_i].data+0).fix_precision().share(bob, alice).get())\n",
    "\n",
    "        new_param = (spdz_params[0] + spdz_params[1]).get().decode()/2\n",
    "        new_params.append(new_param)\n",
    "\n",
    "    for model in params:\n",
    "        for param in model:\n",
    "            param.data *= 0\n",
    "\n",
    "    for model in models:\n",
    "        model.get()\n",
    "\n",
    "        model.divide_clip_grads()\n",
    "        model.add_noise_to_grads()\n",
    "\n",
    "    for remote_index in range(len(compute_nodes)):\n",
    "        for param_index in range(len(params[remote_index])):\n",
    "            params[remote_index][param_index].data.set_(new_params[param_index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_gUp-uFfwGL"
   },
   "source": [
    "# Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TNED3GD6Y3Va"
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    models[0].eval()\n",
    "    test_loss = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = models[0](data)\n",
    "        test_loss += F.mse_loss(output, target.float(), size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}\\n'.format(test_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EmvTEpIbfzoC"
   },
   "source": [
    "# Training The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1094
    },
    "colab_type": "code",
    "id": "9JWkpGtoY48Y",
    "outputId": "4c6fbc4d-29f4-42bb-cd43-e7a76d8ea04e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[22 19  2 20 12 13  5  4]\n",
      "[ 6  1 17 23  3 24 10 21]\n",
      "[ 7  8  0  9 11 16 14 18]\n",
      "Train Lot: 1 [0/24 (0%)]\tLoss: 647.384460\n",
      "[EpsDelta(spent_eps=0.35977892078031964, spent_delta=1e-05)]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "40594546125",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-1e4d3ffb9c35>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(lot_idx)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mremote_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mworker_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremote_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mremote_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mremote_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mremote_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mremote_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlot_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnew_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-a85cd6695b4f>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(worker_dataset, model, optimizer, lot_idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Note that because we apply backward() several times without resetting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-8534c9ddfac7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/torch/hook.py\u001b[0m in \u001b[0;36m_execute_function_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_execute_function_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0mworker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_self\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_execute_function_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py\u001b[0m in \u001b[0;36m_execute_call\u001b[0;34m(self, attr, self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;31m# performing the operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyft_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0mtorch_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menforce_owner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/torch/tensor.py\u001b[0m in \u001b[0;36mhandle_call\u001b[0;34m(cls, syft_command, owner)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;31m# Else we send the command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_torch_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0mtorch_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_has_only_torch_tensorvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py\u001b[0m in \u001b[0;36msend_torch_command\u001b[0;34m(self, recipient, message)\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;34m*\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0mbeing\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \"\"\"\n\u001b[0;32m-> 1097\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecipient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, recipient, message, framework)\u001b[0m\n\u001b[1;32m   1105\u001b[0m             \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0mmessage_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_cmd'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             \u001b[0mrecipient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m         )\n\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py\u001b[0m in \u001b[0;36msend_msg\u001b[0;34m(self, message, message_type, recipient)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;31m# the message according to the correct protocol (such as HTTPS, Socket,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# or other ways of sending messages).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_wrapper_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecipient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompile_composite_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/virtual.py\u001b[0m in \u001b[0;36m_send_msg\u001b[0;34m(self, message_wrapper_json_binary, recipient)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \"\"\"\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrecipient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceive_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_wrapper_json_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py\u001b[0m in \u001b[0;36mreceive_msg\u001b[0;34m(self, message_wrapper_json)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;31m# load json into a dictionary where all objects have been deserialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mmessage_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_wrapper_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;31m# route message to appropriate logic and execute the command, returning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/encode.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(message, worker, acquire, message_is_dict)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'mode'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mode'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'acquire'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'obj'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'message'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict_message\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/encode.py\u001b[0m in \u001b[0;36mpython_decode\u001b[0;34m(self, dct)\u001b[0m\n\u001b[1;32m    292\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The special object type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is not supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                 \u001b[0mdct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/encode.py\u001b[0m in \u001b[0;36mpython_decode\u001b[0;34m(self, dct)\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;31m# Case of a iter type non json serializable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mobj_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'tuple'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'set'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bytearray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'range'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m                 \u001b[0;31m# Case of a slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mobj_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'slice'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/encode.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;31m# Case of a iter type non json serializable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mobj_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'tuple'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'set'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bytearray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'range'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m                 \u001b[0;31m# Case of a slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mobj_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'slice'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/encode.py\u001b[0m in \u001b[0;36mpython_decode\u001b[0;34m(self, dct)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;31m# Case of a Variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mtorch_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_head\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m                 \u001b[0;31m# Case of a Syft tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mtorch_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_syft_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/torch/tensor.py\u001b[0m in \u001b[0;36mdeser\u001b[0;34m(msg_obj, worker, acquire, is_head)\u001b[0m\n\u001b[1;32m   2136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macquire\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_head\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2137\u001b[0m         \u001b[0mobj_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_type_and_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2138\u001b[0;31m         \u001b[0mvar_syft_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SyftTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeser_routing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'child'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macquire\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvar_syft_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvar_syft_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/torch/tensor.py\u001b[0m in \u001b[0;36mdeser_routing\u001b[0;34m(cls, dct, worker, acquire)\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_LocalTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macquire\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mobj_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'_PointerTensor'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_PointerTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macquire\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0msyft_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'syft.'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobj_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/torch/tensor.py\u001b[0m in \u001b[0;36mdeser\u001b[0;34m(cls, msg_obj, worker, acquire)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;31m# If local, we render the object or syft object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmsg_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0msyft_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_at_location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0macquire\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# If there is data transmission, data being here Pointer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearnenv/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py\u001b[0m in \u001b[0;36mget_obj\u001b[0;34m(self, remote_key)\u001b[0m\n\u001b[1;32m    604\u001b[0m         \"\"\"\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mremote_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m         \u001b[0;31m# Fix ownership if the obj has been modified out of control (like with backward())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0mtorch_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menforce_owner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 40594546125"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    print(epoch)\n",
    "    for lot_idx in range(1, N_LOTS):\n",
    "        train(lot_idx)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ylB9_i-CVZM6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Syft) Denver_Boston_Federated_Training.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
