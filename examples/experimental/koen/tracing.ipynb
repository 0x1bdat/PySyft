{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "neither-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "stone-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.lib.tensor.tensorbase import SyftTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "rolled-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = SyftTensor.FloatTensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-pierce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-employee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "available-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(x, y):\n",
    "    return 2 * x + y\n",
    "\n",
    "traced_foo = torch.jit.trace(foo, (torch.rand(3), torch.rand(3)))\n",
    "\n",
    "@torch.jit.script\n",
    "def bar(x):\n",
    "    return traced_foo(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "chinese-envelope",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.jit.ScriptFunction at 0x7fe36b518d70>,\n",
       " <torch.jit.ScriptFunction at 0x7fe36b518c50>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_foo, bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lyric-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuu(x):\n",
    "    return traced_foo(x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "advanced-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuu_scripted = torch.jit.script(fuu, torch.rand(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "invisible-straight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuu_scripted(torch.tensor([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "closed-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,2])\n",
    "y = torch.tensor([3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rubber-railway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "developed-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model_params(module, params_list, start_param_idx: int=0):\n",
    "    \"\"\" Set params list into model recursively\n",
    "    \"\"\"\n",
    "    param_idx = start_param_idx\n",
    "\n",
    "#     for name, param in module._parameters.items():\n",
    "#         module._parameters[name] = params_list[param_idx]\n",
    "#         param_idx += 1\n",
    "\n",
    "#     for name, child in module._modules.items():\n",
    "#         if child is not None:\n",
    "#             param_idx = set_model_params(child, params_list, param_idx)\n",
    "\n",
    "#     return param_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "northern-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 392)\n",
    "        self.fc2 = nn.Linear(392, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# model = torch.jit.script(Net())\n",
    "model =Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "advisory-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_cross_entropy_with_logits(logits, targets, batch_size):\n",
    "    \"\"\" Calculates softmax entropy\n",
    "        Args:\n",
    "            * logits: (NxC) outputs of dense layer\n",
    "            * targets: (NxC) one-hot encoded labels\n",
    "            * batch_size: value of N, temporarily required because Plan cannot trace .shape\n",
    "    \"\"\"\n",
    "    # numstable logsoftmax\n",
    "    norm_logits = logits - logits.max()\n",
    "    log_probs = norm_logits - norm_logits.exp().sum(dim=1, keepdim=True).log()\n",
    "    # NLL, reduction = mean\n",
    "    return -(targets * log_probs).sum() / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "assured-voluntary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "finnish-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_sgd(param, **kwargs):\n",
    "    return param - kwargs['lr'] * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dress-characterization",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nattribute lookup is not defined on python value of type 'Net':\n  File \"<ipython-input-114-6608da59597e>\", line 7\n\n    # forward pass\n    logits = model.forward(X)\n             ~~~~~~~~~~~~~ <--- HERE\n    \n    # loss\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-6608da59597e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtraining_plan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# inject params into model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     set_model_params(model, model_params)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0m_rcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jit_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateResolutionCallbackFromClosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         fn = torch._C._jit_script_compile(\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0mqualified_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_rcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_default_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m         )\n\u001b[1;32m    942\u001b[0m         \u001b[0;31m# Forward docstrings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \nattribute lookup is not defined on python value of type 'Net':\n  File \"<ipython-input-114-6608da59597e>\", line 7\n\n    # forward pass\n    logits = model.forward(X)\n             ~~~~~~~~~~~~~ <--- HERE\n    \n    # loss\n"
     ]
    }
   ],
   "source": [
    "@torch.jit.script\n",
    "def training_plan(X, y, batch_size, lr, model_params):\n",
    "    # inject params into model\n",
    "#     set_model_params(model, model_params)\n",
    "\n",
    "    # forward pass\n",
    "    logits = model.forward(X)\n",
    "    \n",
    "    # loss\n",
    "    loss = softmax_cross_entropy_with_logits(logits, y, batch_size)\n",
    "\n",
    "    # backprop\n",
    "    loss.backward()\n",
    "\n",
    "    # step\n",
    "    updated_params = [\n",
    "        naive_sgd(param, lr=lr)\n",
    "        for param in model_params\n",
    "    ]\n",
    "    \n",
    "    # accuracy\n",
    "    pred = th.argmax(logits, dim=1)\n",
    "    target = th.argmax(y, dim=1)\n",
    "    acc = pred.eq(target).sum().float() / batch_size\n",
    "\n",
    "    return (\n",
    "        loss,\n",
    "        acc,\n",
    "        *updated_params\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "robust-pilot",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-80-f44551d57a08>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-80-f44551d57a08>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    model = my_script_module = torch.jit.trace(Net(), (,))\u001b[0m\n\u001b[0m                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model = my_script_module = torch.jit.trace(Net(), (,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "equivalent-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = [param.data for param in model.parameters()] \n",
    "\n",
    "x = torch.rand((32, 784,392))\n",
    "y = torch.randint(0, 10, (32,10))\n",
    "bs, lr = 32, 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "checked-andorra",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nCannot call a ScriptModule that is not a submodule of the caller:\n  File \"<ipython-input-48-76a76cc55314>\", line 3\ndef training_plan(X, y, batch_size, lr, model_params):\n    # inject params into model\n    set_model_params(model, model_params)\n                     ~~~~~ <--- HERE\n\n    # forward pass\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-ae4a405e4a0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_plan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/pysyft/lib/python3.7/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0m_rcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jit_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateResolutionCallbackFromClosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         fn = torch._C._jit_script_compile(\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0mqualified_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_rcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_default_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m         )\n\u001b[1;32m    942\u001b[0m         \u001b[0;31m# Forward docstrings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \nCannot call a ScriptModule that is not a submodule of the caller:\n  File \"<ipython-input-48-76a76cc55314>\", line 3\ndef training_plan(X, y, batch_size, lr, model_params):\n    # inject params into model\n    set_model_params(model, model_params)\n                     ~~~~~ <--- HERE\n\n    # forward pass\n"
     ]
    }
   ],
   "source": [
    "torch.jit.script(training_plan, (x, y, bs, lr, model_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-leonard",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
