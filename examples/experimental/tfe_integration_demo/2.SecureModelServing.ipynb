{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Secure Model Serving with Syft Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a trained model with normal Keras, you are ready to serve some private predictions. We can do that using Syft Keras. \n",
    "\n",
    "The first step is to define your Syft Keras model, like we did in the previous notebook. However, there is a trick: before instantiating this model, we'll run `hook = sy.KerasHook(tf.keras)`. By doing this, this function will add three important new methods to the Keras package:\n",
    " - `share`: it will transform your model in a TF Encrypted Keras model. Basically it will be an encrypted version of the exact same model you had before with the capability of providing predictions on encrypted data.\n",
    " - `serve`: by running this function your model will be ready to run predictions on encrypted data \n",
    " - `shutdown_workers`: once you are done providing private predictions, you can shut down your model by running this function\n",
    " \n",
    "To secure and serve this model, we will need three TFEWorkers (servers), because under the hood, TF Encrypted is using an encryption technique called [multi-party computation (MPC)](https://en.wikipedia.org/wiki/Secure_multi-party_computation). The idea is to split the model weights and input data into shares, then send a share of each value to the different servers. The key property is that if you look at the share on one server, it reveals nothing about the original value (input data or model weights).\n",
    "\n",
    "If you want learn more about MPC, you can read this excellent [blog](https://mortendahl.github.io/2017/04/17/private-deep-learning-with-mpc/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow (1.13.1). Fix this by compiling custom ops.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import AveragePooling2D, Conv2D, Dense, Activation, Flatten, ReLU, Activation\n",
    "\n",
    "import syft as sy\n",
    "hook = sy.KerasHook(tf.keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we define almost the exact same model as before, except we provide a batch_input_shape. The main reason is because TFE expects fully defined tensors. For this demo will send input data with the shape of [1, 28, 28, 1]. \n",
    "We also return the logit instead of softmax because this operation hasn't been yet implemented in TFE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_classes = 10\n",
    "task_shape = [1, 28, 28, 1]\n",
    "pre_trained_weights = 'short-conv-mnist.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/pysyft_36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/pysyft_36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(10, (3, 3), batch_input_shape=task_shape))\n",
    "model.add(AveragePooling2D((2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(AveragePooling2D((2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(AveragePooling2D((2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(task_classes, name=\"logit\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `load_weights` you can easily load the weights you have saved previously after training your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(pre_trained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's know create TFEWorkers (alice, bob and carol) required by TFE to perform private predictions. For each TFEWorker, you just have to specify a host. When creating them, you should see a message asking you to run a command in a terminal for each worker. By running these commands, it will create a [TensorFlow server](https://www.tensorflow.org/api_docs/python/tf/distribute/Server) for each of them. \n",
    "\n",
    "If you prefer to have these TFEWorkers launched automatically, you can just set `AUTO = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tf_encrypted:Please launch the following command in a terminal owned by this worker:\n",
      "`python -m tf_encrypted.player --config /tmp/tfe.config server0`\n",
      "This can be done automatically in a local subprocess by setting the `autolaunch` kwarg to True when instantiating a TFEWorker.\n",
      "INFO:tf_encrypted:Please launch the following command in a terminal owned by this worker:\n",
      "`python -m tf_encrypted.player --config /tmp/tfe.config server1`\n",
      "This can be done automatically in a local subprocess by setting the `autolaunch` kwarg to True when instantiating a TFEWorker.\n",
      "INFO:tf_encrypted:Please launch the following command in a terminal owned by this worker:\n",
      "`python -m tf_encrypted.player --config /tmp/tfe.config server2`\n",
      "This can be done automatically in a local subprocess by setting the `autolaunch` kwarg to True when instantiating a TFEWorker.\n"
     ]
    }
   ],
   "source": [
    "AUTO = False\n",
    "alice = sy.TFEWorker(host='localhost:4000', autolaunch=AUTO)\n",
    "bob = sy.TFEWorker(host='localhost:4001', autolaunch=AUTO)\n",
    "carol = sy.TFEWorker(host='localhost:4002', autolaunch=AUTO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secure the model by sharing the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to `sy.KerasHook(tf.keras)` you can call the `share` method to trasnform your model into a TFE Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tf_encrypted:Starting session on target 'grpc://localhost:4000' using config graph_options {\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.share(alice, bob, carol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serve model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! now by calling `model.serve1`, your model is ready to provide some private predictions. You can set `num_steps` depending on how many private predictions you are expecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Served\n",
      "Served\n",
      "Served\n"
     ]
    }
   ],
   "source": [
    "model.serve(num_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are ready to move to the **3.PrivatePredictionClient** notebook to request some private predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are done querying the model, you can kill the workers by executing the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if AUTO:\n",
    "    model.shutdown_workers()\n",
    "else:\n",
    "    import subprocess\n",
    "    subprocess.run([\"kill\",\"$(ps aux | grep '[p]ython -m tf_encrypted.player --config /tmp/tfe.config*' | awk '{print $2}')\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
