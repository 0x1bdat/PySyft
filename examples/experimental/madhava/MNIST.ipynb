{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madhavajay/.local/share/virtualenvs/PySyft-lHlz_cKe/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:125: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "from syft.lib import python\n",
    "sy.VERBOSE = False\n",
    "from syft.core.common.uid import UID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alice = sy.VirtualMachine(name=\"alice\")\n",
    "alice_client = alice.get_root_client()\n",
    "alice.root_verify_key = alice_client.verify_key  # inject üì°üîë as üìçüóù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# original MNIST imports\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torchvision import datasets, transforms\n",
    "# from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# get imports from remote client to match\n",
    "torch = alice_client.torch\n",
    "torchvision = alice_client.torchvision\n",
    "transforms = torchvision.transforms\n",
    "datasets = torchvision.datasets\n",
    "nn = torch.nn\n",
    "F = torch.nn.functional\n",
    "optim = torch.optim\n",
    "StepLR = torch.optim.lr_scheduler.StepLR\n",
    "Net = alice_client.models.MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper to create and send a primitive\n",
    "def make(thing):\n",
    "    prim = python.primitive_factory.PrimitiveFactory.generate_primitive(value=thing, recurse=True)\n",
    "    ptr = prim.send(alice_client)\n",
    "    return ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(alice.store.peek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  > <UID:6f1ef041-fdab-4209-adf6-ee8283b7e38b> <UID:üö¥üöÜ> => üóÇÔ∏è (StorableObject) (MNIST())\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "print(alice.store.peek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "params = model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<syft.proxy.torch.TensorPointer object at 0x1360fe2b0> <class 'syft.proxy.torch.TensorPointer'>\n"
     ]
    }
   ],
   "source": [
    "# N X C, H, W\n",
    "# make some data\n",
    "list_ptr = make([64, 1, 28, 28])\n",
    "x = torch.ones(list_ptr)\n",
    "print(x, type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<syft.proxy.models.MNISTPointer at 0x136054be0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  > <UID:6f1ef041-fdab-4209-adf6-ee8283b7e38b> <UID:üö¥üöÜ> => üóÇÔ∏è (StorableObject) (MNIST())\n",
      "\n",
      "  > <UID:b7a4639d-a523-4ecb-aab5-0d47e25ade69> <UID:üö∫üöØ> => üóÇÔ∏è (StorableObject) (MNIST())\n",
      "\n",
      "  > <UID:0ee71ffc-eb3f-4bb5-9fc3-50713d4509d0> <UID:üôøüöÇ> => üóÇÔ∏è (StorableObject) (<generator object Module.parameters at 0x13605b270>)\n",
      "\n",
      "  > <UID:0d9720a7-b6bb-45d3-ab41-edd4c93e39e2> <UID:üöÖüö∂> => üóÇÔ∏è (StorableObject) ([64, 1, 28, 28] can_read: ['üöç', 'üú°'])\n",
      "\n",
      "  > <UID:f040f1de-505c-4bac-9423-3f15486fa56f> <UID:üö¥üöä> => üóÇÔ∏è (StorableObject) (tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]]]) can_read: ['üöç', 'üú°'])\n",
      "\n",
      "  > <UID:e4bfe5e2-21fe-4db3-ac47-9f83d3f37724> <UID:üôñüö≤> => üóÇÔ∏è (StorableObject) (tensor([[-2.4202, -2.6252, -2.5730, -2.1762, -2.0051, -2.1290, -2.4331, -2.2137,\n",
      "         -2.2920, -2.3314],\n",
      "        [-2.2447, -2.4071, -2.4652, -2.1840, -2.1957, -2.2122, -2.4570, -2.3489,\n",
      "         -2.2958, -2.2654],\n",
      "        [-2.2444, -2.4252, -2.4547, -2.2014, -2.2654, -2.1617, -2.2767, -2.3733,\n",
      "         -2.2785, -2.3873],\n",
      "        [-2.2273, -2.4484, -2.4745, -2.2139, -2.1283, -2.1584, -2.5176, -2.3721,\n",
      "         -2.2149, -2.3579],\n",
      "        [-2.4093, -2.5445, -2.3142, -2.1583, -1.9963, -2.1790, -2.3779, -2.3997,\n",
      "         -2.3085, -2.4609],\n",
      "        [-2.3679, -2.5762, -2.2675, -2.2448, -2.1216, -2.0875, -2.3686, -2.3395,\n",
      "         -2.3419, -2.3993],\n",
      "        [-2.1724, -2.3788, -2.3600, -2.2523, -2.2477, -2.2465, -2.4197, -2.2749,\n",
      "         -2.3413, -2.3594],\n",
      "        [-2.2268, -2.4953, -2.3922, -2.1605, -2.2621, -2.1519, -2.4891, -2.3261,\n",
      "         -2.3069, -2.2795],\n",
      "        [-2.3585, -2.5419, -2.4066, -2.2592, -1.9999, -2.1890, -2.5133, -2.1844,\n",
      "         -2.3777, -2.3179],\n",
      "        [-2.3615, -2.5499, -2.4627, -2.1728, -2.2144, -2.2331, -2.4023, -2.2059,\n",
      "         -2.2376, -2.2559],\n",
      "        [-2.2274, -2.4766, -2.4329, -2.1703, -2.2109, -2.2173, -2.3815, -2.2937,\n",
      "         -2.4036, -2.2629],\n",
      "        [-2.2274, -2.4539, -2.3363, -2.3492, -2.1706, -2.2272, -2.3503, -2.3617,\n",
      "         -2.3397, -2.2424],\n",
      "        [-2.3524, -2.4531, -2.3345, -2.2504, -2.0960, -2.2586, -2.3823, -2.3050,\n",
      "         -2.2975, -2.3375],\n",
      "        [-2.3341, -2.6359, -2.2908, -2.2753, -2.1123, -2.2602, -2.4813, -2.1399,\n",
      "         -2.2518, -2.3467],\n",
      "        [-2.2973, -2.4716, -2.4096, -2.1879, -2.2577, -2.1609, -2.3524, -2.3366,\n",
      "         -2.3425, -2.2507],\n",
      "        [-2.3133, -2.4613, -2.4852, -2.2294, -2.2111, -2.1651, -2.3707, -2.2384,\n",
      "         -2.3347, -2.2670],\n",
      "        [-2.2500, -2.4225, -2.3348, -2.1762, -2.2432, -2.1553, -2.4508, -2.3002,\n",
      "         -2.4063, -2.3329],\n",
      "        [-2.3481, -2.5212, -2.3661, -2.2657, -2.2269, -2.2068, -2.2773, -2.3183,\n",
      "         -2.3113, -2.2217],\n",
      "        [-2.1627, -2.4708, -2.4837, -2.1540, -2.1824, -2.0962, -2.5403, -2.3582,\n",
      "         -2.3768, -2.3122],\n",
      "        [-2.2235, -2.6663, -2.1715, -2.2905, -2.1420, -2.2405, -2.4862, -2.1947,\n",
      "         -2.3906, -2.3327],\n",
      "        [-2.2720, -2.3614, -2.4609, -2.2417, -2.2716, -2.2145, -2.3831, -2.3177,\n",
      "         -2.2798, -2.2487],\n",
      "        [-2.2625, -2.5307, -2.3029, -2.2434, -2.1061, -2.1520, -2.4521, -2.2701,\n",
      "         -2.4308, -2.3549],\n",
      "        [-2.3456, -2.6758, -2.3214, -2.1379, -2.1527, -2.2587, -2.4869, -2.1971,\n",
      "         -2.2527, -2.3098],\n",
      "        [-2.2710, -2.4467, -2.2856, -2.2468, -2.1991, -2.2050, -2.3847, -2.3609,\n",
      "         -2.4157, -2.2458],\n",
      "        [-2.2851, -2.3910, -2.4144, -2.1611, -2.2331, -2.1690, -2.3178, -2.3926,\n",
      "         -2.3971, -2.3054],\n",
      "        [-2.3231, -2.4650, -2.4994, -2.2051, -2.2359, -2.1824, -2.3322, -2.3625,\n",
      "         -2.2883, -2.1869],\n",
      "        [-2.2530, -2.5056, -2.3668, -2.1721, -2.2919, -2.2582, -2.3233, -2.3795,\n",
      "         -2.2031, -2.3132],\n",
      "        [-2.3485, -2.4640, -2.3121, -2.2359, -2.1795, -2.3102, -2.3156, -2.2097,\n",
      "         -2.3100, -2.3709],\n",
      "        [-2.2881, -2.6150, -2.4317, -2.1298, -2.1059, -2.2017, -2.4329, -2.4319,\n",
      "         -2.2806, -2.2220],\n",
      "        [-2.1550, -2.5396, -2.5048, -2.2204, -2.1758, -2.2067, -2.3744, -2.3613,\n",
      "         -2.2168, -2.3535],\n",
      "        [-2.1596, -2.4203, -2.4694, -2.2535, -2.1795, -2.1294, -2.3848, -2.4727,\n",
      "         -2.2968, -2.3328],\n",
      "        [-2.2416, -2.6032, -2.3925, -2.2126, -2.2151, -2.1386, -2.4030, -2.2151,\n",
      "         -2.3603, -2.3236],\n",
      "        [-2.3248, -2.6161, -2.3643, -2.1632, -2.2165, -2.2156, -2.3062, -2.3837,\n",
      "         -2.2145, -2.2928],\n",
      "        [-2.2077, -2.5367, -2.3057, -2.2530, -2.2087, -2.2130, -2.3598, -2.2701,\n",
      "         -2.4533, -2.2711],\n",
      "        [-2.2362, -2.4773, -2.3539, -2.0992, -2.3147, -2.2048, -2.4422, -2.2525,\n",
      "         -2.3720, -2.3314],\n",
      "        [-2.2615, -2.5332, -2.3847, -2.2546, -2.1310, -2.1269, -2.3028, -2.4264,\n",
      "         -2.3504, -2.3250],\n",
      "        [-2.2316, -2.5018, -2.4236, -2.2506, -2.1999, -2.2228, -2.3371, -2.2089,\n",
      "         -2.3055, -2.3912],\n",
      "        [-2.1946, -2.4653, -2.5141, -2.2587, -2.2058, -2.1527, -2.5076, -2.2456,\n",
      "         -2.3675, -2.1998],\n",
      "        [-2.2047, -2.4515, -2.3706, -2.2135, -2.1652, -2.1802, -2.5178, -2.2961,\n",
      "         -2.3611, -2.3284],\n",
      "        [-2.2381, -2.5064, -2.3732, -2.2269, -2.0808, -2.1869, -2.4774, -2.2964,\n",
      "         -2.5232, -2.2176],\n",
      "        [-2.2273, -2.6055, -2.4418, -2.1673, -2.1420, -2.1146, -2.4288, -2.2311,\n",
      "         -2.3530, -2.4294],\n",
      "        [-2.3332, -2.4855, -2.4512, -2.1442, -1.9885, -2.0963, -2.5150, -2.3455,\n",
      "         -2.4461, -2.3722],\n",
      "        [-2.2480, -2.5737, -2.3569, -2.1645, -2.3012, -2.2210, -2.4347, -2.2979,\n",
      "         -2.2425, -2.2473],\n",
      "        [-2.1964, -2.4736, -2.4887, -2.2927, -2.1064, -2.0812, -2.4923, -2.3984,\n",
      "         -2.3005, -2.3000],\n",
      "        [-2.2812, -2.4771, -2.4888, -2.2598, -2.2488, -2.2062, -2.3824, -2.3996,\n",
      "         -2.1433, -2.2029],\n",
      "        [-2.2428, -2.5164, -2.4379, -2.1733, -2.0898, -2.0620, -2.4287, -2.4788,\n",
      "         -2.3249, -2.3942],\n",
      "        [-2.3165, -2.5955, -2.4276, -2.1532, -2.1005, -2.0582, -2.4545, -2.4331,\n",
      "         -2.3370, -2.2824],\n",
      "        [-2.3245, -2.4284, -2.4799, -2.2047, -2.2510, -2.2165, -2.2369, -2.3302,\n",
      "         -2.2616, -2.3287],\n",
      "        [-2.3163, -2.5908, -2.3853, -2.0614, -2.0906, -2.2940, -2.4550, -2.1853,\n",
      "         -2.3229, -2.4500],\n",
      "        [-2.2655, -2.4871, -2.3752, -2.2394, -2.1638, -2.1844, -2.4512, -2.3425,\n",
      "         -2.2926, -2.2744],\n",
      "        [-2.3568, -2.4297, -2.4492, -2.2130, -2.0747, -2.1975, -2.4048, -2.3611,\n",
      "         -2.2935, -2.3097],\n",
      "        [-2.1954, -2.4930, -2.3221, -2.3109, -2.2075, -2.1360, -2.3631, -2.2654,\n",
      "         -2.4299, -2.3570],\n",
      "        [-2.3269, -2.4399, -2.2934, -2.2194, -2.2089, -2.2138, -2.2940, -2.3461,\n",
      "         -2.3940, -2.3161],\n",
      "        [-2.2430, -2.4617, -2.5269, -2.2089, -2.1470, -2.1370, -2.4039, -2.4242,\n",
      "         -2.2748, -2.2802],\n",
      "        [-2.1704, -2.4517, -2.5239, -2.2058, -2.1527, -2.2126, -2.4066, -2.2163,\n",
      "         -2.3738, -2.3905],\n",
      "        [-2.3504, -2.6218, -2.2182, -2.3638, -2.0942, -2.3146, -2.4999, -2.0812,\n",
      "         -2.3101, -2.2924],\n",
      "        [-2.3875, -2.4066, -2.4962, -2.3085, -2.1665, -2.0347, -2.3939, -2.2772,\n",
      "         -2.3396, -2.2957],\n",
      "        [-2.2863, -2.4105, -2.5052, -2.3075, -2.1612, -2.0927, -2.4350, -2.3863,\n",
      "         -2.2509, -2.2633],\n",
      "        [-2.1724, -2.5013, -2.4215, -2.3054, -2.2319, -2.1457, -2.3396, -2.3490,\n",
      "         -2.3559, -2.2569],\n",
      "        [-2.1972, -2.4637, -2.5289, -2.2477, -2.2477, -2.2700, -2.3586, -2.3361,\n",
      "         -2.2716, -2.1627],\n",
      "        [-2.2780, -2.4643, -2.4396, -2.1486, -2.1337, -2.1163, -2.4229, -2.4263,\n",
      "         -2.3142, -2.3660],\n",
      "        [-2.3262, -2.7137, -2.2079, -2.2804, -2.2525, -2.3630, -2.3846, -2.2624,\n",
      "         -2.1778, -2.1623],\n",
      "        [-2.3491, -2.5253, -2.5127, -2.1097, -2.1204, -2.2786, -2.4062, -2.2133,\n",
      "         -2.2509, -2.3541],\n",
      "        [-2.3596, -2.5199, -2.3970, -2.1919, -2.1675, -2.0954, -2.3819, -2.3425,\n",
      "         -2.3194, -2.3219]], grad_fn=<LogSoftmaxBackward>))\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(alice.store.peek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.Adadelta(params, lr=make(1.0))\n",
    "# TODO fix ValueError: optimizer got an empty parameter list\n",
    "# might be incorrect return type for methods and properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<syft.proxy.torch.nn.Conv2dPointer object at 0x136149cd0> <class 'syft.proxy.torch.nn.Conv2dPointer'>\n"
     ]
    }
   ],
   "source": [
    "conv1 = nn.Conv2d(make(1), make(32), make(3), make(1))\n",
    "print(conv1, type(conv1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test all the Functional methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<syft.proxy.torch.TensorPointer object at 0x136149370> <class 'syft.proxy.torch.TensorPointer'>\n"
     ]
    }
   ],
   "source": [
    "# N X C, H, W\n",
    "# make some data\n",
    "list_ptr2 = make([32, 1, 3, 3])\n",
    "g = torch.ones(list_ptr)\n",
    "print(g, type(g))\n",
    "\n",
    "x = conv1(g)\n",
    "x = F.relu(x)\n",
    "x = F.relu(x)\n",
    "x = F.max_pool2d(x, make(2))\n",
    "x = torch.flatten(x, make(1))\n",
    "x = F.relu(x)\n",
    "output = F.log_softmax(x, dim=make(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<syft.proxy.torch.TensorPointer object at 0x1361468b0> <class 'syft.proxy.torch.TensorPointer'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madhavajay/dev/PySyft/src/syft/lib/torch/uppercase_tensor.py:54: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  grad = getattr(self.value, \"grad\", None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-8.8684, -8.8684, -8.8684,  ..., -8.9113, -8.9113, -8.9113],\n",
      "        [-8.8684, -8.8684, -8.8684,  ..., -8.9113, -8.9113, -8.9113],\n",
      "        [-8.8684, -8.8684, -8.8684,  ..., -8.9113, -8.9113, -8.9113],\n",
      "        ...,\n",
      "        [-8.8684, -8.8684, -8.8684,  ..., -8.9113, -8.9113, -8.9113],\n",
      "        [-8.8684, -8.8684, -8.8684,  ..., -8.9113, -8.9113, -8.9113],\n",
      "        [-8.8684, -8.8684, -8.8684,  ..., -8.9113, -8.9113, -8.9113]])\n"
     ]
    }
   ],
   "source": [
    "# get the output\n",
    "print(output, type(output))\n",
    "\n",
    "result = output.get()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL MNIST NET\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self) -> None:\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "#         self.dropout1 = nn.Dropout2d(0.25)\n",
    "#         self.dropout2 = nn.Dropout2d(0.5)\n",
    "#         self.fc1 = nn.Linear(9216, 128)\n",
    "#         self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.max_pool2d(x, 2)\n",
    "#         x = self.dropout1(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.fc2(x)\n",
    "#         output = F.log_softmax(x, dim=1)\n",
    "#         return output\n",
    "\n",
    "# define a Network using make\n",
    "# class Net(nn.Module):\n",
    "# # class Net:\n",
    "#     def __init__(self) -> None:\n",
    "#         self.conv1 = nn.Conv2d(make(1), make(32), make(3), make(1))\n",
    "#         self.conv2 = nn.Conv2d(make(32), make(64), make(3), make(1))\n",
    "#         self.dropout1 = nn.Dropout2d(make(0.25))\n",
    "#         self.dropout2 = nn.Dropout2d(make(0.5))\n",
    "#         self.fc1 = nn.Linear(make(9216), make(128))\n",
    "#         self.fc2 = nn.Linear(make(128), make(10))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.max_pool2d(x, make(2))\n",
    "#         x = self.dropout1(x)\n",
    "#         x = torch.flatten(x, make(1))\n",
    "#         x = self.fc1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.fc2(x)\n",
    "#         output = F.log_softmax(x, dim=make(1))\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ORIGINAL TRAIN\n",
    "# def train(args, model, device, train_loader, optimizer, epoch):\n",
    "#     model.train()\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         loss = F.nll_loss(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         if batch_idx % args.log_interval == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.item()))\n",
    "#             if args.dry_run:\n",
    "#                 break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ORIGINAL TEST\n",
    "# def test(model, device, test_loader):\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in test_loader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             output = model(data)\n",
    "#             test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "#             pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "\n",
    "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         test_loss, correct, len(test_loader.dataset),\n",
    "#         100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fix issue with \n",
    "transform_1 = torchvision.transforms.ToTensor()\n",
    "transform_2 = torchvision.transforms.Normalize(make(0.1307), make(0.3081))\n",
    "\n",
    "# transform_list = make([transform_1, transform_2])\n",
    "# print(type(transform_list), transform_list)\n",
    "# fix cant store pointer? what to do?\n",
    "# transform = torchvision.transforms.Compose(make([transform_1, transform_2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# utility to convert config to pointers\n",
    "# todo replace with Dict\n",
    "# need to fix TypeError: 'DictPointer' object is not subscriptable first\n",
    "def wrap_args_dict(args: dict) -> dict:\n",
    "    wrapped_args = {}\n",
    "    for k, v in args.items():\n",
    "        if sy.lib.python.primitive_factory.isprimitive(v):\n",
    "            wrapped_args[k] = make(v)\n",
    "    return wrapped_args\n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "    plain_args = {\"batch_size\":64, \"test_batch_size\":1000,\n",
    "            \"epochs\":14, \"lr\":1.0, \"gamma\":0.7,\n",
    "            \"no_cuda\":True, \"dry_run\":False, \"seed\":42,\n",
    "            \"log_interval\":10, \"save_model\":False}\n",
    "\n",
    "    args = wrap_args_dict(plain_args)\n",
    "\n",
    "    use_cuda = not plain_args[\"no_cuda\"] and torch.cuda.is_available()\n",
    "    device_type_ptr = make(\"cuda\" if use_cuda else \"cpu\")\n",
    "    torch.manual_seed(args[\"seed\"])\n",
    "\n",
    "    device = torch.device(device_type_ptr)\n",
    "    print(\"device pointer\", device)\n",
    "\n",
    "    kwargs = {'batch_size': args[\"batch_size\"]}\n",
    "    if use_cuda:\n",
    "        kwargs.update(\n",
    "            wrap_args_dict(\n",
    "                {\n",
    "                    'num_workers': 1,\n",
    "                    'pin_memory': True,\n",
    "                    'shuffle': True\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    transform_1 = torchvision.transforms.ToTensor()\n",
    "    transform_2 = torchvision.transforms.Normalize(make(0.1307), make(0.3081))\n",
    "\n",
    "    # fix cant store pointer? what to do?\n",
    "    # transform = torchvision.transforms.Compose(make([transform_1, transform_2]))\n",
    "\n",
    "    dataset1 = datasets.MNIST(make('../data'), train=make(True), download=make(True))\n",
    "                       #transform=transform)\n",
    "    dataset2 = datasets.MNIST(make('../data'), train=make(False))\n",
    "#                        transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **kwargs)\n",
    "\n",
    "    \n",
    "    model = Net()\n",
    "    model = model.to(device)\n",
    "    # optimizer = optim.Adadelta(model.parameters(), lr=args[\"lr\"])\n",
    "    # TODO fix ValueError: optimizer got an empty parameter list\n",
    "    # might be incorrect return type for methods and properties\n",
    "\n",
    "    # scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "#     for epoch in range(1, args[\"epochs\"].get() + 1):\n",
    "#         train(args, model, device, train_loader, optimizer, epoch)\n",
    "#         test(model, device, test_loader)\n",
    "#         scheduler.step()\n",
    "\n",
    "#     if args[\"save_model\"]:\n",
    "#         torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device pointer <syft.proxy.torch.devicePointer object at 0x1365614f0>\n",
      "<syft.proxy.models.MNISTPointer object at 0x136579af0> <class 'syft.proxy.models.MNISTPointer'>\n",
      "<syft.proxy.models.MNISTPointer object at 0x136579a90> <class 'syft.proxy.models.MNISTPointer'>\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
