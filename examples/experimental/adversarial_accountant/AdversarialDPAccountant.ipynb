{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols, pprint\n",
    "from sympy import diff\n",
    "from sympy.solvers import solve\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "import string\n",
    "import random\n",
    "\n",
    "# global espilon budget\n",
    "overall_budget_limit = 5\n",
    "\n",
    "# data subject\n",
    "class Entity():\n",
    "    def __init__(self, name=\"\", id=None):\n",
    "        self.name = name\n",
    "        self.id = id\n",
    "\n",
    "scalar_name2obj = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_RDP_gaussian(params, alpha):\n",
    "    \"\"\"\n",
    "    :param params:\n",
    "        'sigma' --- is the normalized noise level: std divided by global L2 sensitivity\n",
    "    :param alpha: The order of the Renyi Divergence\n",
    "    :return: Evaluation of the RDP's epsilon\n",
    "    \"\"\"\n",
    "    sigma = params['sigma']\n",
    "    value = params['value']\n",
    "    L = params['L']\n",
    "    assert(sigma > 0)\n",
    "    assert(alpha >= 0)\n",
    "    \n",
    "    return (alpha * (L ** 2) * (value**2)) / (2 * (sigma**2))\n",
    "\n",
    "import math\n",
    "\n",
    "from autodp.autodp_core import Mechanism\n",
    "from autodp import rdp_bank, dp_bank, fdp_bank, utils\n",
    "from autodp import transformer_zoo\n",
    "\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "\n",
    "# Example of a specific mechanism that inherits the Mechanism class\n",
    "class iDPGaussianMechanism(Mechanism):\n",
    "    def __init__(self, sigma, value, L, entity, name='Gaussian',\n",
    "                 RDP_off=False, approxDP_off=False, fdp_off=True,\n",
    "                 use_basic_RDP_to_approxDP_conversion=False,\n",
    "                 use_fDP_based_RDP_to_approxDP_conversion=False):\n",
    "        # the sigma parameter is the std of the noise divide by the l2 sensitivity\n",
    "        Mechanism.__init__(self)\n",
    "\n",
    "        self.name = name # When composing\n",
    "        self.params = {'sigma': sigma, 'value':value, 'L':L} # This will be useful for the Calibrator\n",
    "        self.entity = entity\n",
    "        # TODO: should a generic unspecified mechanism have a name and a param dictionary?\n",
    "\n",
    "        self.delta0 = 0\n",
    "        if not RDP_off:\n",
    "            new_rdp = lambda x: individual_RDP_gaussian({'sigma': sigma,\n",
    "                                                        'value': value,\n",
    "                                                        'L':L}, x)\n",
    "            if use_fDP_based_RDP_to_approxDP_conversion:\n",
    "                # This setting is slightly more complex, which involves converting RDP to fDP,\n",
    "                # then to eps-delta-DP via the duality\n",
    "                self.propagate_updates(new_rdp, 'RDP', fDP_based_conversion=True)\n",
    "            elif use_basic_RDP_to_approxDP_conversion:\n",
    "                self.propagate_updates(new_rdp, 'RDP', BBGHS_conversion=False)\n",
    "            else:\n",
    "                # This is the default setting with fast computation of RDP to approx-DP\n",
    "                self.propagate_updates(new_rdp, 'RDP')\n",
    "\n",
    "        if not approxDP_off: # Direct implementation of approxDP\n",
    "            new_approxdp = lambda x: dp_bank.get_eps_ana_gaussian(sigma, x)\n",
    "            self.propagate_updates(new_approxdp,'approxDP_func')\n",
    "\n",
    "        if not fdp_off: # Direct implementation of fDP\n",
    "            fun1 = lambda x: fdp_bank.log_one_minus_fdp_gaussian({'sigma': sigma}, x)\n",
    "            fun2 = lambda x: fdp_bank.log_neg_fdp_grad_gaussian({'sigma': sigma}, x)\n",
    "            self.propagate_updates([fun1,fun2],'fDP_and_grad_log')\n",
    "            # overwrite the fdp computation with the direct computation\n",
    "            self.fdp = lambda x: fdp_bank.fDP_gaussian({'sigma': sigma}, x)\n",
    "\n",
    "        # the fDP of gaussian mechanism is equivalent to analytical calibration of approxdp,\n",
    "        # so it should have been automatically handled numerically above\n",
    "\n",
    "\n",
    "        # Discussion:  Sometimes delta as a function of eps has a closed-form solution\n",
    "        # while eps as a function of delta does not\n",
    "        # Shall we represent delta as a function of eps instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(func, **kwargs):\n",
    "    return func.subs(kwargs)\n",
    "\n",
    "def run_specific(f, **kwargs):\n",
    "    \"\"\"pass in kwargs to run in fixed polynomial because this is what\n",
    "    optimize.brute expects\"\"\"\n",
    "    return run(f, **kwargs)\n",
    "\n",
    "class Scalar():\n",
    "    \n",
    "    def __init__(self, value, min_val=None, max_val=None, poly=None, ent=None, name=None):\n",
    "        \n",
    "        if name is None:\n",
    "            lower_upper_alphabet = string.ascii_letters\n",
    "            name = ''.join([random.choice(lower_upper_alphabet) for i in range(5)])\n",
    "        \n",
    "        self.name = name\n",
    "        self.value = value\n",
    "        self.min_val = min_val\n",
    "        self.max_val = max_val\n",
    "        \n",
    "        if poly is not None:\n",
    "            # if this Scalar is being formed as a function of other Scalar objects\n",
    "            self.poly = poly\n",
    "            \n",
    "        elif ent is not None:\n",
    "            # if you're creating a Scalar for the first time (no parents)\n",
    "            self.scalar_name = self.name + \"_\" + ent.name\n",
    "            self.poly = symbols(self.scalar_name)\n",
    "            scalar_name2obj[self.scalar_name] = self            \n",
    "        else:\n",
    "            raise Exception(\"Poly or ent must be not None\")\n",
    "\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        \n",
    "        result_poly = self.poly * other.poly\n",
    "        result_value = self.value * other.value\n",
    "        \n",
    "        result = Scalar(value=result_value, poly=result_poly)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        result_poly = self.poly + other.poly\n",
    "        result_value = self.value + other.value\n",
    "        \n",
    "        result = Scalar(value=result_value, poly=result_poly)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        result_poly = self.poly - other.poly\n",
    "        result_value = self.value - other.value\n",
    "        \n",
    "        result = Scalar(value=result_value, poly=result_poly)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.poly) + \"=\" + str(self.value)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "    @property\n",
    "    def sens(self):\n",
    "        if self.min_val is not None and self.max_val is not None:\n",
    "            return self.max_val - self.min_val\n",
    "\n",
    "    def neg_deriv(self, name):\n",
    "        obj = scalar_name2obj[name]\n",
    "        return -diff(self.poly, obj.poly)\n",
    "        \n",
    "\n",
    "    def create_run_specific_args(self, f):\n",
    "\n",
    "        free_symbols_list = list(self.poly.free_symbols)\n",
    "        index2symbol = list(map(lambda x:str(x), free_symbols_list))\n",
    "\n",
    "        symbol2index = {}\n",
    "        for i,sym in enumerate(index2symbol):\n",
    "            symbol2index[sym] = i\n",
    "\n",
    "        def _run_specific_args(tuple_of_args, *params):\n",
    "            kwargs = {}\n",
    "            for sym,i in symbol2index.items():\n",
    "                kwargs[sym] = tuple_of_args[i]\n",
    "\n",
    "            return run_specific(f=f, **kwargs)\n",
    "\n",
    "        return _run_specific_args, index2symbol, symbol2index\n",
    "    \n",
    "    def get_mechanism(self,\n",
    "            symbol_name = 'b',\n",
    "            sigma = 0.1,\n",
    "            granularity = 0.5):\n",
    "        \n",
    "        # Step 1: get derivative we want to maximize\n",
    "        z = self.neg_deriv(symbol_name)\n",
    "\n",
    "        # Step 2: prepare metadata for optimize.brute() function\n",
    "        sy_names = z.free_symbols\n",
    "        sym = list()\n",
    "        for sy_name in sy_names:\n",
    "            sym.append(scalar_name2obj[str(sy_name)])\n",
    "\n",
    "        run_specific_args, index2symbol, symbol2index = self.create_run_specific_args(f=z)\n",
    "\n",
    "        rranges = list()\n",
    "        for i,sym in enumerate(index2symbol):\n",
    "            obj = scalar_name2obj[sym]\n",
    "            rranges.append(slice(obj.min_val, obj.max_val, granularity))\n",
    "        \n",
    "        # Step 3: maximize the derivative over a bounded range of <entity_name>\n",
    "        resbrute = optimize.brute(run_specific_args,rranges, full_output=False, finish=None, disp=True)\n",
    "\n",
    "        L = resbrute[symbol2index[symbol_name]]\n",
    "        input_obj = scalar_name2obj[symbol_name]\n",
    "\n",
    "        # Step 4: create the gaussian mechanism object\n",
    "        gm1 = iDPGaussianMechanism(sigma=sigma, value=input_obj.value, L=L, entity=symbol_name.split(\"_\")[1], name='gm_'+symbol_name)\n",
    "\n",
    "        return gm1\n",
    "    \n",
    "    def get_all_entity_mechanisms(self,sigma=0.1,granularity=0.5):\n",
    "        sy_names = self.poly.free_symbols\n",
    "        entity2mechanisms = {}\n",
    "        for sy_name in sy_names:\n",
    "            mechanism = self.get_mechanism(symbol_name=str(sy_name), sigma=sigma, granularity=granularity)\n",
    "            \n",
    "            split_name = str(sy_name).split(\"_\")\n",
    "            entity_name = split_name[1]\n",
    "            var_name = split_name[0]\n",
    "            \n",
    "            if entity_name not in entity2mechanisms.keys():\n",
    "                entity2mechanisms[entity_name] = list()\n",
    "            \n",
    "            entity2mechanisms[entity_name].append(mechanism)\n",
    "            \n",
    "            \n",
    "        return entity2mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialAccountant():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.entity2ledger = {}\n",
    "        self.max_budget = 10\n",
    "\n",
    "    def append(self, entity2mechanisms):\n",
    "        for key, ms in entity2mechanisms.items():\n",
    "            if key not in self.entity2ledger.keys():\n",
    "                self.entity2ledger[key] = list()\n",
    "            for m in ms:\n",
    "                self.entity2ledger[key].append(m)\n",
    "    \n",
    "    def get_eps_for_entity(self, entity_name, delta=1e-6):\n",
    "        # compose them with the transformation: compose.\n",
    "        compose = Composition()\n",
    "        mechanisms = self.entity2ledger[entity_name]\n",
    "        composed_mech = compose(mechanisms, [1]*len(mechanisms))\n",
    "\n",
    "        # Query for eps given delta\n",
    "        return Scalar(value=composed_mech.get_approxDP(delta1), \n",
    "                      min_val=0, \n",
    "                      max_val=self.max_budget,\n",
    "                      ent=Entity(name=entity_name))\n",
    "        \n",
    "    def print_ledger(self, delta=1e-6):\n",
    "        for entity, mechanisms in self.entity2ledger.items():\n",
    "            print(entity + \"\\t\" + str(self.get_eps_for_entity(entity, delta=delta).value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob = Scalar(value=1, min_val=-2, max_val=2, ent=Entity(name=\"Bob\"))\n",
    "alice = Scalar(value=1, min_val=-1, max_val=1, ent=Entity(name=\"Alice\"))\n",
    "charlie = Scalar(value=2, min_val=-2, max_val=2, ent=Entity(name=\"Charlie\"))\n",
    "dan = Scalar(value=-1, min_val=-2, max_val=2, ent=Entity(name=\"David\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = bob * bob * bob + charlie + dan + bob + alice\n",
    "\n",
    "ms = out.get_all_entity_mechanisms(sigma=1.5, granularity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = AdversarialAccountant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc.append(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice\t3.318643635391174\n",
      "David\t7.25415714907092\n",
      "Charlie\t16.59912949887057\n",
      "Bob\t7.25415714907092\n"
     ]
    }
   ],
   "source": [
    "acc.print_ledger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: try numpy.roots approach to solving for max derivative definitively\n",
    "# https://numpy.org/doc/stable/reference/generated/numpy.roots.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
