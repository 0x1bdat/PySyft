{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping torch.torch.Tensor.__div__ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.__floordiv__ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.__rfloordiv__ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_and not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_and_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_or not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_or_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.div not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.div_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.floor_divide not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.floor_divide_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.is_meta not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_and not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_and_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_or not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_or_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.remainder not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.remainder_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.square not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.square_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.true_divide not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.true_divide_ not supported in 1.4.0\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import copy\n",
    "from sympy import symbols\n",
    "import random\n",
    "sy.VERBOSE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤  ðŸŽ¸  â™ªâ™ªâ™ª starting duet â™«â™«â™«  ðŸŽ»  ðŸŽ¹\n",
      "\n",
      "â™«â™«â™« >\u001b[93m DISCLAIMER\u001b[0m:\u001b[1m Duet is an experimental feature currently \n",
      "â™«â™«â™« > in alpha. Do not use this to protect real-world data.\n",
      "\u001b[0mâ™«â™«â™« >\n",
      "â™«â™«â™« > Punching through firewall to OpenGrid Network Node at network_url: \n",
      "â™«â™«â™« > http://ec2-18-216-8-163.us-east-2.compute.amazonaws.com:5000\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > ...waiting for response from OpenGrid Network... Skipping torch.torch.Tensor.__div__ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.__floordiv__ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.__rfloordiv__ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_and not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_and_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_or not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_or_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.div not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.div_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.floor_divide not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.floor_divide_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.is_meta not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_and not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_and_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_or not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_or_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.remainder not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.remainder_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.square not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.square_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.true_divide not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.true_divide_ not supported in 1.4.0\n",
      "\u001b[92mDONE!\u001b[0m\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > \u001b[95mSTEP 1:\u001b[0m Send the following code to your duet partner!\n",
      "\n",
      "import syft as sy\n",
      "sy.VERBOSE=False\n",
      "duet = sy.join_duet('\u001b[1mdd5ceeca4cc8222973da48f8cc2e315c\u001b[0m')\n",
      "\n",
      "â™«â™«â™« > \u001b[95mSTEP 2:\u001b[0m The code above will print out a 'Client Id'. Have\n",
      "â™«â™«â™« >         your duet partner send it to you and enter it below!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "duet = sy.launch_duet()\n",
    "# duet = sy.launch_duet(budget_database='~./duet/privacy_budgets.db')\n",
    "# duet.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "def gen_privscal(value, entity, range_min=0., range_max=10.):\n",
    "    # generate private scalar\n",
    "    p_id = str(entity) + str(PrivateScalar.create_id())\n",
    "    x = {entity:{p_id:value}}\n",
    "    g = symbols(p_id)\n",
    "    f = {entity:{p_id:range_min}} \n",
    "    c = {entity:{p_id:range_max}}\n",
    "    return PrivateScalar(x, g, f, c, p_id)\n",
    "\n",
    "def concat_nestdicts(a, b):\n",
    "    # concatenate 2 nested dictionaries\n",
    "    x = {}\n",
    "    for ent, val_dict in a.items():\n",
    "        x[ent] = copy.deepcopy(val_dict)\n",
    "    for ent, val_dict  in b.items():\n",
    "        if ent not in x:\n",
    "            x[ent] = copy.deepcopy(val_dict)\n",
    "        else:\n",
    "            for val_id, val in val_dict.items():\n",
    "                x[ent][val_id] = val\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrivateScalar:\n",
    "    \n",
    "    def __init__(self, x, g, f, c, p_id):\n",
    "        \n",
    "        self.p_id = p_id\n",
    "        self.x = x # intermediate data\n",
    "        self.g = g # polynomial\n",
    "        self.f = f # lower bound val\n",
    "        self.c = c # upper bound class\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(\"<p_id: \" + self.p_id \n",
    "                   + \" x: \" + str(self.x)\n",
    "                   + \" g: \" + str(self.g)\n",
    "                   + \" f: \" + str(self.f)\n",
    "                   + \" c: \" + str(self.c)\n",
    "                  + \">\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_id():\n",
    "        return str(random.randint(0, 1e10))\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        x = concat_nestdicts(self.x, other.x)\n",
    "        f = concat_nestdicts(self.f, other.f)\n",
    "        c = concat_nestdicts(self.c, other.c)\n",
    "        g = self.g + other.g\n",
    "        p_id = self.create_id()\n",
    "        return PrivateScalar(x, g, f, c, p_id)\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        x = concat_nestdicts(self.x, other.x)\n",
    "        f = concat_nestdicts(self.f, other.f)\n",
    "        c = concat_nestdicts(self.c, other.c)\n",
    "        g = self.g * other.g\n",
    "        p_id = self.create_id()\n",
    "        return PrivateScalar(x, g, f, c, p_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p_id: 405173733 x: {'bob': {'bob4140844245': 1.5}, 'andrew': {'andrew2620106328': 3}} g: andrew2620106328*bob4140844245>\n",
      "<p_id: 5028770490 x: {'bob': {'bob4140844245': 1.5}, 'andrew': {'andrew2620106328': 3}} g: andrew2620106328 + bob4140844245>\n",
      "<p_id: bob4140844245 x: {'bob': {'bob4140844245': 1.5}} g: bob4140844245>\n",
      "<p_id: andrew2620106328 x: {'andrew': {'andrew2620106328': 3}} g: andrew2620106328>\n"
     ]
    }
   ],
   "source": [
    "# Example testing\n",
    "\n",
    "x = [1.5, 2, 3, 4, 5]\n",
    "entities = ['bob', 'kriti', 'andrew', 'bob', 'amber'] # every value corresponds to an entity\n",
    "num_entities = len(entities) # ??? number of unique entities instead\n",
    "priv_a = gen_privscal(x[0], entities[0])\n",
    "priv_b = gen_privscal(x[2], entities[2])\n",
    "print(priv_a * priv_b)\n",
    "print(priv_a + priv_b)\n",
    "print(priv_a)\n",
    "print(priv_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RDP_Accountant:\n",
    "    \n",
    "    def __init__(self, entities, num_unique_entities, ac_id, l2_norm, alpha, lipschitz, sigma, data_profile):\n",
    "        self.act_id = ac_id\n",
    "        self.data_profile = data_profile # every row, column or value corresponds to an entity\n",
    "        self.entities = entities # dic\n",
    "        self.num_unique_entities = num_unique_entities\n",
    "        self.num_entities = len(entities)\n",
    "        # num_entities >= num_unique_entities\n",
    "        \n",
    "        # below budget values are upper bounds (remaining at the start)\n",
    "        self.data_budget = th.tensor([1.] * num_entities)\n",
    "        self.global_data_budget = 10.0\n",
    "        self.scientist_budget = th.tensor([0.1] * num_entities)\n",
    "        self.global_scientist_budget = 2.0\n",
    "        \n",
    "        self.rdp_guarantee = th.tensor([0.] * num_entities)\n",
    "        self.global_rdp_guarantee = 0.\n",
    "        self.l2_norm = l2_norm # array of values per entity\n",
    "        self.alpha = alpha # alpha > 1.0 \n",
    "        self.lipschitz = lipschitz # array of values per entity\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        # current value of budget spent per entity \n",
    "        self.eps = (alpha * (l2_norm ** 2) * (lipschitz ** 2)) / (2 * (sigma ** 2)) \n",
    "        # array of values per entity\n",
    "        \n",
    "    def update_budgets(self):\n",
    "        self.data_budget -= self.eps\n",
    "        self.rdp_guarantee = self.eps\n",
    "    \n",
    "#     def public_approx_Renyi_filter(self, max_rounds):\n",
    "#         # input: public approx list of chosen epsilons and deltas (per round), \n",
    "#         #        public global epsilon & delta, round of computation t / T individual filtering \n",
    "#         # output: Continue / Halt execution\n",
    "#         return True\n",
    "    \n",
    "    def public_approx_Renyi_odometer(self, max_rounds):\n",
    "        # gives a valid upper bound on the privacy loss incurred thus far\n",
    "        # input: round of computation t / T\n",
    "        \n",
    "        # add upper and lower bounds on the below values of budget remaining\n",
    "#         data_budget = th.tensor([1.] * num_entities)\n",
    "#         global_data_budget = 10.0\n",
    "#         scientist_budget = th.tensor([0.1] * num_entities)\n",
    "#         global_scientist_budget = 2.0\n",
    "        rdp_guarantee = tuple(alpha, eps)\n",
    "        return rdp_guarantee\n",
    "    \n",
    "    def add_laplacian_noise(self, eps, l1_sens):\n",
    "        return 1.0\n",
    "    \n",
    "    def add_gaussian_noise(self, eps, l2_sens, delta):\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle x + 1$"
      ],
      "text/plain": [
       "x + 1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PrivateTensor:\n",
    "    \n",
    "    # each row is a data point, number of data points = no. of columns. 2-D tensor\n",
    "    def __init__(self, tensor, min_tensor, max_tensor, entity_cont, num_entities):\n",
    "        self.data = tensor\n",
    "        self.entity_cont = entity_cont # entity contribution to each data point \n",
    "        # self.data[i] = sum over all j entity_cont[i][j]\n",
    "        self.data_min = min_tensor\n",
    "        self.data_max = max_tensor\n",
    "        self.lipschitz = []\n",
    "        self.l2_norm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duet.budget\n",
    "\n",
    "print(\"OVERALL - Per Scientist Entity Budget:\" + str(3))\n",
    "print(\"OVERALL - Universal Entity Budget:\" + str(5))\n",
    "print()\n",
    "print(\"EST. REMAINING - MIN Universal Entity Budget:\" + str(4.2))\n",
    "print(\"EST. REMAINING - MAX Universal Entity Budget:\" + str(4.9))\n",
    "print(\"EST. REMAINING - MEAN Universal Entity Budget:\" + str(4.21))\n",
    "print()\n",
    "print(\"EST. REMAINING - MIN Per Scientist Entity Budget:\" + str(2.91))\n",
    "print(\"EST. REMAINING - MAX Per Scientist Entity Budget:\" + str(3.0))\n",
    "print(\"EST. REMAINING - MEAN Per Scientist Entity Budget:\" + str(2.92))\n",
    "\n",
    "# estimated budget spend for this tensor\n",
    "print(\"EST SPEND - MIN Per Scientist Entity Budget:\" + str(0))\n",
    "print(\"EST SPEND - MAX Per Scientist Entity Budget:\" + str(0))\n",
    "print(\"EST SPEND - MEAN Per Scientist Entity Budget:\" + str(0.12))\n",
    "\n",
    "# show analytics again as percentage ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figuring stuff out\n",
    "x = [1, 2, 3, 4]\n",
    "y = [2, 4, 6, 7]\n",
    "ent_x = [bob, andrew, amber, bob]\n",
    "y = sum(x) + x[0]\n",
    "y = 2 * bob[0] + andrew[0] + amber[0] # this is wrong\n",
    "\n",
    "# from sympy import symbols\n",
    "x, y = symbols('x y')\n",
    "print(x)\n",
    "print(y)\n",
    "print(y * (x * 2))\n",
    "\n",
    "expr = x + y\n",
    "# expr = expr.subs(x, 0)\n",
    "# expr = expr.subs(y, 1)\n",
    "expr.evalf(subs={x: 2.4, y:0})\n",
    "# expr\n",
    "# print(expr)\n",
    "\n",
    "# ages = th.tensor([23,52,31,16]).tag(\"ages\").private(every_value_unique_entity=True, # every_row_unique_entity=False,\n",
    "#                                             # every_column_unique_entity=False,\n",
    "#                                             max_value=125, min_value=0).send(duet, searchable=True)\n",
    "# # ages.entities by default equals = [acc.n_entities+0,acc.n_entities+1,acc.n_entities+2,acc.n_entities+3]\n",
    "# heights = th.tensor([150,160,140,100]).tag(\"heights\").private(every_value_unique_entity=True, max_value=250, \n",
    "#                                             min_value=0, entities=ages.entities).send(duet, searchable=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
