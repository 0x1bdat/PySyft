{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import torch as th\n",
    "import numpy as np\n",
    "sy.VERBOSE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤  ðŸŽ¸  â™ªâ™ªâ™ª starting duet â™«â™«â™«  ðŸŽ»  ðŸŽ¹\n",
      "\n",
      "â™«â™«â™« >\u001b[93m DISCLAIMER\u001b[0m:\u001b[1m Duet is an experimental feature currently \n",
      "â™«â™«â™« > in alpha. Do not use this to protect real-world data.\n",
      "\u001b[0mâ™«â™«â™« >\n",
      "â™«â™«â™« > Punching through firewall to OpenGrid Network Node at network_url: \n",
      "â™«â™«â™« > http://ec2-18-216-8-163.us-east-2.compute.amazonaws.com:5000\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > ...waiting for response from OpenGrid Network... Skipping torch.torch.Tensor.__div__ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.__floordiv__ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.__rfloordiv__ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_and not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_and_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_or not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_or_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.div not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.div_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.floor_divide not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.floor_divide_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.is_meta not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_and not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_and_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_or not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_or_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.remainder not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.remainder_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.square not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.square_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.true_divide not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.true_divide_ not supported in 1.4.0\n",
      "\u001b[92mDONE!\u001b[0m\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > \u001b[95mSTEP 1:\u001b[0m Send the following code to your duet partner!\n",
      "\n",
      "import syft as sy\n",
      "sy.VERBOSE=False\n",
      "duet = sy.join_duet('\u001b[1m204867b15ec3b7a479b9c681c827a7a5\u001b[0m')\n",
      "\n",
      "â™«â™«â™« > \u001b[95mSTEP 2:\u001b[0m The code above will print out a 'Client Id'. Have\n",
      "â™«â™«â™« >         your duet partner send it to you and enter it below!\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "â™«â™«â™« > Duet Partner's Client Id: 7b2e4c1ae26dd0d35f516db21880132c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â™«â™«â™« > Connecting...\n",
      "â™«â™«â™« > ...using a running event loop...\n",
      "Skipping torch.torch.Tensor.__div__ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.__floordiv__ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.__rfloordiv__ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_and not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_and_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_or not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_or_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.div not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.div_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.floor_divide not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.floor_divide_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.is_meta not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_and not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_and_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_or not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_or_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.remainder not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.remainder_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.square not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.square_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.true_divide not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.true_divide_ not supported in 1.4.0\n",
      "\n",
      "â™«â™«â™« > \u001b[92mCONNECTED!\u001b[0m\n",
      "Skipping torch.torch.Tensor.__div__ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.__floordiv__ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.__rfloordiv__ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_and not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_and_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_or not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.bitwise_or_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.div not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.div_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.floor_divide not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.floor_divide_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.is_meta not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_and not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_and_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_or not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.logical_or_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.remainder not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.remainder_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.square not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.square_ not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.true_divide not supported in 1.4.0\n",
      "Skipping torch.torch.Tensor.true_divide_ not supported in 1.4.0\n",
      "\n",
      "â™«â™«â™« > DUET LIVE STATUS  *  Objects: 0  Requests: 0   Messages: 3                                "
     ]
    }
   ],
   "source": [
    "duet = sy.launch_duet()\n",
    "\n",
    "# duet = sy.launch_duet(per_scientist_per_entity_epsilon_budget=3,\n",
    "#                       universal_per_entity_epsilon_budget=5,\n",
    "#                       budget_database='~./duet/privacy_budgets.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = th.tensor([[1., 2.], \n",
    "                  [2., 4.], \n",
    "                  [3., 7.], \n",
    "                  [9., 12.]])\n",
    "print(data.shape)\n",
    "entities = ['alice', 'bob', 'charlie', 'david']\n",
    "print(len(entities))\n",
    "num_entities = len(entities)\n",
    "duet.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = th.tensor([23,52,31,16]).tag(\"ages\").private(every_value_unique_entity=True,\n",
    "                                                    every_row_unique_entity=False,\n",
    "                                                    every_column_unique_entity=False,\n",
    "                                                    max_value=125,\n",
    "                                                    min_value=0).send(duet, searchable=True)\n",
    "\n",
    "# ages.entities by default equals = [acc.n_entities+0,acc.n_entities+1,acc.n_entities+2,acc.n_entities+3]\n",
    "\n",
    "heights = th.tensor([150,160,140,100]).tag(\"heights\").private(every_value_unique_entity=True,\n",
    "                                                              max_value=250, \n",
    "                                                              min_value=0, \n",
    "                                                              entities=ages.entities).send(duet, searchable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RDP_Accountant:\n",
    "    \n",
    "    def __init__(self, num_entities):\n",
    "        self.data_budget = th.tensor([1.] * num_entities)\n",
    "        self.global_data_budget = 10.0\n",
    "        \n",
    "        self.scientist_budget = th.tensor([0.1] * num_entities)\n",
    "        self.global_scientist_budget = 2.0\n",
    "        \n",
    "        self.rdp_guarantee = th.tensor([0.] * num_entities)\n",
    "        self.global_rdp_guarantee = 0.\n",
    "    \n",
    "    def get_current_rdp_guarantee(self):\n",
    "        return tuple(rdp_guarantee, global_rdp_guarantee)\n",
    "    \n",
    "    def public_approx_Renyi_filter(self, max_rounds):\n",
    "\n",
    "        # input: public approx list of chosen epsilons and deltas (per round), \n",
    "        #        public global epsilon & delta,\n",
    "        #        round of computation t / T\n",
    "        # individual filtering \n",
    "        # output: Continue / Halt execution\n",
    "        return True\n",
    "    \n",
    "    def public_approx_Renyi_odometer(self, max_rounds):\n",
    "\n",
    "        # gives a valid upper bound on the privacy loss incurred thus far\n",
    "        # input: round of computation t / T\n",
    "        rdp_guarantee = tuple(alpha, eps)\n",
    "        return rdp_guarantee\n",
    "    \n",
    "    def add_gaussian_noise(self, eps, delta, l2_sens):\n",
    "        return 1.0\n",
    "        \n",
    "    def add_laplacian_noise(self, eps, l1_sens):\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class PrivateScalar:\n",
    "    \n",
    "    def __init__(self, x, g, f, c, p_id):\n",
    "        \n",
    "        self.p_id = p_id\n",
    "        self.x = x # intermediate data\n",
    "        self.g = g # polynomial\n",
    "        self.f = f # lower bound val\n",
    "        self.c = c # upper bound class\n",
    "        \n",
    "    def __repr__(self):\n",
    "        \n",
    "        return str(\"<p_id: \" + self.p_id \n",
    "                   + \" x: \" + str(self.x)\n",
    "                   + \" g: \" + str(self.g)\n",
    "#                    + \" f: \" + str(self.f)\n",
    "#                    + \" c: \" + str(self.c)\n",
    "                  + \">\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_id():\n",
    "        return str(random.randint(0, 1e10))\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        x = concat_nestdicts(self.x, other.x)\n",
    "        f = concat_nestdicts(self.f, other.f)\n",
    "        c = concat_nestdicts(self.c, other.c)\n",
    "        g = self.g + other.g\n",
    "        p_id = self.create_id()\n",
    "        return PrivateScalar(x, g, f, c, p_id)\n",
    "\n",
    "def concat_nestdicts(a, b):\n",
    "    x = {}\n",
    "    for ent, val_dict in a.items():\n",
    "        x[ent] = copy.deepcopy(val_dict)\n",
    "    for ent, val_dict  in b.items():\n",
    "        if ent not in x:\n",
    "            x[ent] = copy.deepcopy(val_dict)\n",
    "        else:\n",
    "            for val_id, val in val_dict.items():\n",
    "                x[ent][val_id] = val\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p_id: 9959622508 x: {'bob': {'bob2442327234': 1, 'bob7723779859': 4}} g: bob2442327234 + bob7723779859>\n",
      "<p_id: bob2442327234 x: {'bob': {'bob2442327234': 1}} g: bob2442327234>\n",
      "<p_id: bob7723779859 x: {'bob': {'bob7723779859': 4}} g: bob7723779859>\n"
     ]
    }
   ],
   "source": [
    "x = [1, 2, 3, 4, 5]\n",
    "entities = ['bob', 'kriti', 'andrew', 'bob', 'amber']\n",
    "priv_a = gen_privscal(x[0], entities[0])\n",
    "priv_b = gen_privscal(x[3], entities[3])\n",
    "print(priv_a + priv_b)\n",
    "print(priv_a)\n",
    "print(priv_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def gen_privscal(value, entity, range_min=0., range_max=10.):\n",
    "\n",
    "    p_id = str(entity) + str(PrivateScalar.create_id())\n",
    "    x = {entity:{p_id:value}}\n",
    "    g = symbols(p_id)\n",
    "    f = {entity:{p_id:range_min}} \n",
    "    c = {entity:{p_id:range_max}}\n",
    "    return PrivateScalar(x, g, f, c, p_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3, 4]\n",
    "y = [2, 4, 6, 7]\n",
    "ent_x = [bob, andrew, amber, bob]\n",
    "y = sum(x) + x[0]\n",
    "y = 2 * bob[0] + andrew[0] + amber[0] + bob[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sympy\n",
      "  Downloading sympy-1.6.2-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.8 MB 1.4 MB/s eta 0:00:01     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                        | 1.4 MB 1.3 MB/s eta 0:00:04\n",
      "\u001b[?25hCollecting mpmath>=0.19\n",
      "  Downloading mpmath-1.1.0.tar.gz (512 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512 kB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: mpmath\n",
      "  Building wheel for mpmath (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mpmath: filename=mpmath-1.1.0-py3-none-any.whl size=532239 sha256=ffe297a438afc8271049a980f2f7e308a6102f8c57b0d3619a0824d73c95cf24\n",
      "  Stored in directory: /home/kritika/.cache/pip/wheels/e2/46/78/e78f76c356bca9277368f1f97a31b37a8cb937176d9511af31\n",
      "Successfully built mpmath\n",
      "Installing collected packages: mpmath, sympy\n",
      "Successfully installed mpmath-1.1.0 sympy-1.6.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "y\n",
      "2*x*y\n"
     ]
    }
   ],
   "source": [
    "# from sympy import symbols\n",
    "x, y = symbols('x y')\n",
    "print(x)\n",
    "print(y)\n",
    "print(y * (x * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2.4$"
      ],
      "text/plain": [
       "2.40000000000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr = x + y\n",
    "# expr = expr.subs(x, 0)\n",
    "# expr = expr.subs(y, 1)\n",
    "expr.evalf(subs={x: 2.4, y:0})\n",
    "# expr\n",
    "# print(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle x + 1$"
      ],
      "text/plain": [
       "x + 1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "# class PrivateTensor:\n",
    "    \n",
    "#     # each row is a data point, number of data points = no. of columns. 2-D tensor\n",
    "#     def __init__(self, tensor, min_tensor, max_tensor, entity_cont, num_entities):\n",
    "#         self.data = tensor\n",
    "#         self.entity_cont = entity_cont # entity contribution to each data point \n",
    "#         # self.data[i] = sum over all j entity_cont[i][j]\n",
    "#         self.data_min = min_tensor\n",
    "#         self.data_max = max_tensor\n",
    "#         self.lipschitz = []\n",
    "#         self.l2_norm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# duet.budget\n",
    "\n",
    "print(\"OVERALL - Per Scientist Entity Budget:\" + str(3))\n",
    "print(\"OVERALL - Universal Entity Budget:\" + str(5))\n",
    "print()\n",
    "print(\"EST. REMAINING - MIN Universal Entity Budget:\" + str(4.2))\n",
    "print(\"EST. REMAINING - MAX Universal Entity Budget:\" + str(4.9))\n",
    "print(\"EST. REMAINING - MEAN Universal Entity Budget:\" + str(4.21))\n",
    "print()\n",
    "print(\"EST. REMAINING - MIN Per Scientist Entity Budget:\" + str(2.91))\n",
    "print(\"EST. REMAINING - MAX Per Scientist Entity Budget:\" + str(3.0))\n",
    "print(\"EST. REMAINING - MEAN Per Scientist Entity Budget:\" + str(2.92))\n",
    "\n",
    "# estimated budget spend for this tensor\n",
    "print(\"EST SPEND - MIN Per Scientist Entity Budget:\" + str(0))\n",
    "print(\"EST SPEND - MAX Per Scientist Entity Budget:\" + str(0))\n",
    "print(\"EST SPEND - MEAN Per Scientist Entity Budget:\" + str(0.12))\n",
    "\n",
    "# show analytics again as percentage ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
