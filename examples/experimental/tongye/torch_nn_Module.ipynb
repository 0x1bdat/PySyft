{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import torch as th\n",
    "from syft.core.plan.plan_builder import make_plan\n",
    "from syft.lib.python.collections import OrderedDict\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-24T10:19:34.145871+0800][CRITICAL][logger]][872] Skipping torchvision.torchvision.transforms.functional.adjust_sharpness not supported in 0.8.1\n",
      "[2021-03-24T10:19:34.146279+0800][CRITICAL][logger]][872] Skipping torchvision.torchvision.transforms.functional.autocontrast not supported in 0.8.1\n",
      "[2021-03-24T10:19:34.146533+0800][CRITICAL][logger]][872] Skipping torchvision.torchvision.transforms.functional.equalize not supported in 0.8.1\n",
      "[2021-03-24T10:19:34.146826+0800][CRITICAL][logger]][872] Skipping torchvision.torchvision.transforms.functional.invert not supported in 0.8.1\n",
      "[2021-03-24T10:19:34.147087+0800][CRITICAL][logger]][872] Skipping torchvision.torchvision.transforms.functional.posterize not supported in 0.8.1\n",
      "[2021-03-24T10:19:34.147354+0800][CRITICAL][logger]][872] Skipping torchvision.torchvision.transforms.functional.solarize not supported in 0.8.1\n"
     ]
    }
   ],
   "source": [
    "alice = sy.VirtualMachine()\n",
    "alice_client = alice.get_root_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----fc_ptr----\n",
      "<syft.proxy.torch.nn.LinearPointer object at 0x7ffddd7651c0>\n",
      "\n",
      "----res_ptr----\n",
      "<syft.proxy.torch.TensorPointer object at 0x7ffe801e63d0>\n",
      "\n",
      "----res_ptr.get()----\n",
      "tensor([[0.8382, 0.8850]], requires_grad=True)\n",
      "\n",
      "----fc_ptr.get().state_dict()----\n",
      "OrderedDict([('weight', tensor([[-0.2090, -0.0208,  0.4798, -0.2642],\n",
      "        [ 0.2569, -0.0775,  0.0796, -0.4728]])), ('bias', tensor([-0.2466,  0.0769]))])\n",
      "\n",
      "----sd2----\n",
      "OrderedDict([('weight', tensor([[-0.2090, -0.0208,  0.4798, -0.2642],\n",
      "        [ 0.2569, -0.0775,  0.0796, -0.4728]])), ('bias', tensor([-0.2466,  0.0769]))])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/github/PySyft/src/syft/lib/torch/uppercase_tensor.py:30: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  grad = getattr(obj, \"grad\", None)\n"
     ]
    }
   ],
   "source": [
    "# Linear\n",
    "fc = th.nn.Linear(4,2)\n",
    "\n",
    "# send\n",
    "fc_ptr = fc.send(alice_client)\n",
    "print(f\"----fc_ptr----\\n{fc_ptr}\\n\")\n",
    "\n",
    "# remote call\n",
    "res_ptr = fc_ptr(th.rand([1,4]))\n",
    "print(f\"----res_ptr----\\n{res_ptr}\\n\")\n",
    "print(f\"----res_ptr.get()----\\n{res_ptr.get()}\\n\")\n",
    "\n",
    "# remote update state dict\n",
    "sd2 = OrderedDict(th.nn.Linear(4,2).state_dict())\n",
    "sd2_ptr = sd2.send(alice_client)\n",
    "fc_ptr.load_state_dict(sd2_ptr)\n",
    "\n",
    "# get\n",
    "print(f\"----fc_ptr.get().state_dict()----\\n{fc_ptr.get().state_dict()}\\n\")\n",
    "print(f\"----sd2----\\n{sd2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-24T10:19:34.277944+0800][CRITICAL][logger]][872] <class 'syft.core.store.store_memory.MemoryStore'> __delitem__ error <UID: 348a2be75cda41058bf18e4fcbdce253>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----relu_ptr----\n",
      "<syft.proxy.torch.nn.ReLUPointer object at 0x7ffddd815760>\n",
      "\n",
      "----res_ptr----\n",
      "<syft.proxy.torch.TensorPointer object at 0x7ffe801e6e80>\n",
      "\n",
      "----res_ptr.get()----\n",
      "tensor([[0.8725, 0.4835, 0.6143, 0.2234]])\n",
      "\n",
      "----relu_ptr.get()----\n",
      "ReLU(inplace=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ReLU\n",
    "relu = th.nn.ReLU(inplace=True)\n",
    "\n",
    "# send\n",
    "relu_ptr = relu.send(alice_client)\n",
    "print(f\"----relu_ptr----\\n{relu_ptr}\\n\")\n",
    "\n",
    "# remote call\n",
    "res_ptr = relu_ptr(th.rand([1,4]))\n",
    "print(f\"----res_ptr----\\n{res_ptr}\\n\")\n",
    "print(f\"----res_ptr.get()----\\n{res_ptr.get()}\\n\")\n",
    "\n",
    "# get\n",
    "print(f\"----relu_ptr.get()----\\n{relu_ptr.get()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-03-24T10:19:34.304693+0800][CRITICAL][logger]][872] <class 'syft.core.store.store_memory.MemoryStore'> __delitem__ error <UID: a782634d5cdb4f149dc15f385a041753>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----seq_ptr----\n",
      "<syft.proxy.torch.nn.SequentialPointer object at 0x7ffddd7658e0>\n",
      "\n",
      "----res_ptr----\n",
      "<syft.proxy.torch.TensorPointer object at 0x7ffddd765d00>\n",
      "\n",
      "----res_ptr.get()----\n",
      "tensor([[0.1151]], requires_grad=True)\n",
      "\n",
      "----seq_ptr.get().state_dict()----\n",
      "OrderedDict([('fc1.weight', tensor([[ 0.1484, -0.2039, -0.4905,  0.2857],\n",
      "        [-0.2914, -0.0684,  0.1452,  0.0238]])), ('fc1.bias', tensor([-0.2603, -0.0075])), ('fc2.weight', tensor([[-0.3948,  0.3055]])), ('fc2.bias', tensor([-0.5001]))])\n",
      "\n",
      "----sd2----\n",
      "OrderedDict([('fc1.weight', tensor([[ 0.1484, -0.2039, -0.4905,  0.2857],\n",
      "        [-0.2914, -0.0684,  0.1452,  0.0238]])), ('fc1.bias', tensor([-0.2603, -0.0075])), ('fc2.weight', tensor([[-0.3948,  0.3055]])), ('fc2.bias', tensor([-0.5001]))])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sequential\n",
    "seq = th.nn.Sequential()\n",
    "seq.add_module(\"fc1\", th.nn.Linear(4,2))\n",
    "seq.add_module(\"fc2\", th.nn.Linear(2,1))\n",
    "\n",
    "# send\n",
    "seq_ptr = seq.send(alice_client)\n",
    "print(f\"----seq_ptr----\\n{seq_ptr}\\n\")\n",
    "\n",
    "# remote call\n",
    "res_ptr = seq_ptr(th.rand([1,4]))\n",
    "print(f\"----res_ptr----\\n{res_ptr}\\n\")\n",
    "print(f\"----res_ptr.get()----\\n{res_ptr.get()}\\n\")\n",
    "\n",
    "# remote update state dict\n",
    "sd2 = OrderedDict(\n",
    "    th.nn.Sequential(\n",
    "        collections.OrderedDict([\n",
    "            (\"fc1\", th.nn.Linear(4,2)),\n",
    "            (\"fc2\", th.nn.Linear(2,1))\n",
    "        ])\n",
    "    ).state_dict()\n",
    ")\n",
    "sd2_ptr = sd2.send(alice_client)\n",
    "seq_ptr.load_state_dict(sd2_ptr)\n",
    "\n",
    "# get\n",
    "print(f\"----seq_ptr.get().state_dict()----\\n{seq_ptr.get().state_dict()}\\n\")\n",
    "print(f\"----sd2----\\n{sd2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----m_ptr----\n",
      "<syft.proxy.torch.nn.ModulePointer object at 0x7ffddd6364f0>\n",
      "\n",
      "----m_ptr.get()----\n",
      "Module(\n",
      "  (fc1): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# user defined model\n",
    "class M(th.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(M, self).__init__()\n",
    "        self.fc1 = th.nn.Linear(4,2)\n",
    "        self.fc2 = th.nn.Linear(2,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def forward_Plan(self):\n",
    "        @make_plan\n",
    "        def remote_forward(\n",
    "            x=th.rand([4,4]), \n",
    "            fc1 = self.fc1,\n",
    "            fc2 = self.fc2\n",
    "        ):\n",
    "            x = fc1(x)\n",
    "            x = fc2(x)\n",
    "            return x\n",
    "        return remote_forward\n",
    "        \n",
    "m = M()\n",
    "\n",
    "# send\n",
    "m_ptr = m.send(alice_client)\n",
    "print(f\"----m_ptr----\\n{m_ptr}\\n\")\n",
    "\n",
    "# TODO: remote call\n",
    "# res_ptr = m_ptr(x=th.rand([1,25]))\n",
    "# print(f\"----res_ptr----\\n{res_ptr}\\n\")\n",
    "# print(f\"----res_ptr.get()----\\n{res_ptr.get()}\\n\")\n",
    "\n",
    "# get\n",
    "print(f\"----m_ptr.get()----\\n{m_ptr.get()}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
