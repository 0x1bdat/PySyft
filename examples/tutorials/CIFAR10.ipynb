{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load required libraries\n",
    "\n",
    "'''Torch Libraries required to train Neural Network'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "'''Library required to train neural network using federated learning. Syft overloads PyTorch'''\n",
    "\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Setting of Learning Task</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.test_batch_size = 1000\n",
    "        self.epochs = 2\n",
    "        self.lr = 0.01\n",
    "        self.momentum = 0.5\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 10\n",
    "        self.save_model = False\n",
    "        \n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Load and Distribute Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Load_Data():\n",
    "    \n",
    "    '''Load CIFAR dataset from torch vision module and split to training/test set'''\n",
    "    \n",
    "    transform = transforms.Compose(\n",
    "                [transforms.ToTensor(),\n",
    "                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    #Training Dataset\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                              shuffle=True, num_workers=0)\n",
    "    \n",
    "    #Test Dataset\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "    \n",
    "    return (trainloader,testloader)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FederatedDataset(nodes,data):\n",
    "    \n",
    "    '''Distribute the dataset to compute nodes'''\n",
    "    \n",
    "    train_distributed_dataset = []\n",
    "\n",
    "    n_batch = 937\n",
    "\n",
    "    trainloader,testloader=Load_Data()\n",
    "\n",
    "    for batch_idx, (data,target) in enumerate(trainloader):\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(round(100*batch_idx/n_batch), '%')\n",
    "        data = data.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
    "        target = target.send(compute_nodes[batch_idx % len(compute_nodes)])\n",
    "        train_distributed_dataset.append((data, target))\n",
    "        '''if batch_idx > 13000: #TODO rm this limit which is just for dev to have less data to load and train\n",
    "             break'''\n",
    "        \n",
    "    print('Done !')\n",
    "    \n",
    "    return (train_distributed_dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Initialize Workers</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n",
      "WARNING:root:Worker bob already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:root:Worker alice already exists. Replacing old worker which could cause                     unexpected behavior\n"
     ]
    }
   ],
   "source": [
    "#Hook Torch instance with Syft Hook\n",
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "#Initialize workers\n",
    "me = hook.local_worker\n",
    "bob = sy.VirtualWorker(id=\"bob\",hook=hook, is_client_worker=False)\n",
    "alice = sy.VirtualWorker(id=\"alice\",hook=hook, is_client_worker=False)\n",
    "\n",
    "#Define compute nodes\n",
    "compute_nodes = [bob, alice]\n",
    "\n",
    "#Add worker instances\n",
    "me.add_workers([bob, alice])\n",
    "bob.add_workers([me, alice])\n",
    "alice.add_workers([me, bob])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Distribute Data to Workers</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "0 %\n",
      "2 %\n",
      "4 %\n",
      "6 %\n",
      "9 %\n",
      "11 %\n",
      "13 %\n",
      "15 %\n",
      "17 %\n",
      "19 %\n",
      "21 %\n",
      "23 %\n",
      "26 %\n",
      "28 %\n",
      "30 %\n",
      "32 %\n",
      "34 %\n",
      "36 %\n",
      "38 %\n",
      "41 %\n",
      "43 %\n",
      "45 %\n",
      "47 %\n",
      "49 %\n",
      "51 %\n",
      "53 %\n",
      "55 %\n",
      "58 %\n",
      "60 %\n",
      "62 %\n",
      "64 %\n",
      "66 %\n",
      "68 %\n",
      "70 %\n",
      "73 %\n",
      "75 %\n",
      "77 %\n",
      "79 %\n",
      "81 %\n",
      "83 %\n",
      "85 %\n",
      "88 %\n",
      "90 %\n",
      "92 %\n",
      "94 %\n",
      "96 %\n",
      "98 %\n",
      "100 %\n",
      "102 %\n",
      "105 %\n",
      "107 %\n",
      "109 %\n",
      "111 %\n",
      "113 %\n",
      "115 %\n",
      "117 %\n",
      "120 %\n",
      "122 %\n",
      "124 %\n",
      "126 %\n",
      "128 %\n",
      "130 %\n",
      "132 %\n",
      "134 %\n",
      "137 %\n",
      "139 %\n",
      "141 %\n",
      "143 %\n",
      "145 %\n",
      "147 %\n",
      "149 %\n",
      "152 %\n",
      "154 %\n",
      "156 %\n",
      "158 %\n",
      "160 %\n",
      "162 %\n",
      "164 %\n",
      "166 %\n",
      "169 %\n",
      "171 %\n",
      "173 %\n",
      "175 %\n",
      "177 %\n",
      "179 %\n",
      "181 %\n",
      "184 %\n",
      "186 %\n",
      "188 %\n",
      "190 %\n",
      "192 %\n",
      "194 %\n",
      "196 %\n",
      "199 %\n",
      "201 %\n",
      "203 %\n",
      "205 %\n",
      "207 %\n",
      "209 %\n",
      "211 %\n",
      "213 %\n",
      "216 %\n",
      "218 %\n",
      "220 %\n",
      "222 %\n",
      "224 %\n",
      "226 %\n",
      "228 %\n",
      "231 %\n",
      "233 %\n",
      "235 %\n",
      "237 %\n",
      "239 %\n",
      "241 %\n",
      "243 %\n",
      "245 %\n",
      "248 %\n",
      "250 %\n",
      "252 %\n",
      "254 %\n",
      "256 %\n",
      "258 %\n",
      "260 %\n",
      "263 %\n",
      "265 %\n",
      "267 %\n",
      "269 %\n",
      "271 %\n",
      "273 %\n",
      "275 %\n",
      "277 %\n",
      "280 %\n",
      "282 %\n",
      "284 %\n",
      "286 %\n",
      "288 %\n",
      "290 %\n",
      "292 %\n",
      "295 %\n",
      "297 %\n",
      "299 %\n",
      "301 %\n",
      "303 %\n",
      "305 %\n",
      "307 %\n",
      "309 %\n",
      "312 %\n",
      "314 %\n",
      "316 %\n",
      "318 %\n",
      "320 %\n",
      "322 %\n",
      "324 %\n",
      "327 %\n",
      "329 %\n",
      "331 %\n",
      "333 %\n",
      "335 %\n",
      "337 %\n",
      "339 %\n",
      "342 %\n",
      "344 %\n",
      "346 %\n",
      "348 %\n",
      "350 %\n",
      "352 %\n",
      "354 %\n",
      "356 %\n",
      "359 %\n",
      "361 %\n",
      "363 %\n",
      "365 %\n",
      "367 %\n",
      "369 %\n",
      "371 %\n",
      "374 %\n",
      "376 %\n",
      "378 %\n",
      "380 %\n",
      "382 %\n",
      "384 %\n",
      "386 %\n",
      "388 %\n",
      "391 %\n",
      "393 %\n",
      "395 %\n",
      "397 %\n",
      "399 %\n",
      "401 %\n",
      "403 %\n",
      "406 %\n",
      "408 %\n",
      "410 %\n",
      "412 %\n",
      "414 %\n",
      "416 %\n",
      "418 %\n",
      "420 %\n",
      "423 %\n",
      "425 %\n",
      "427 %\n",
      "429 %\n",
      "431 %\n",
      "433 %\n",
      "435 %\n",
      "438 %\n",
      "440 %\n",
      "442 %\n",
      "444 %\n",
      "446 %\n",
      "448 %\n",
      "450 %\n",
      "453 %\n",
      "455 %\n",
      "457 %\n",
      "459 %\n",
      "461 %\n",
      "463 %\n",
      "465 %\n",
      "467 %\n",
      "470 %\n",
      "472 %\n",
      "474 %\n",
      "476 %\n",
      "478 %\n",
      "480 %\n",
      "482 %\n",
      "485 %\n",
      "487 %\n",
      "489 %\n",
      "491 %\n",
      "493 %\n",
      "495 %\n",
      "497 %\n",
      "499 %\n",
      "502 %\n",
      "504 %\n",
      "506 %\n",
      "508 %\n",
      "510 %\n",
      "512 %\n",
      "514 %\n",
      "517 %\n",
      "519 %\n",
      "521 %\n",
      "523 %\n",
      "525 %\n",
      "527 %\n",
      "529 %\n",
      "531 %\n",
      "534 %\n",
      "536 %\n",
      "538 %\n",
      "540 %\n",
      "542 %\n",
      "544 %\n",
      "546 %\n",
      "549 %\n",
      "551 %\n",
      "553 %\n",
      "555 %\n",
      "557 %\n",
      "559 %\n",
      "561 %\n",
      "564 %\n",
      "566 %\n",
      "568 %\n",
      "570 %\n",
      "572 %\n",
      "574 %\n",
      "576 %\n",
      "578 %\n",
      "581 %\n",
      "583 %\n",
      "585 %\n",
      "587 %\n",
      "589 %\n",
      "591 %\n",
      "593 %\n",
      "596 %\n",
      "598 %\n",
      "600 %\n",
      "602 %\n",
      "604 %\n",
      "606 %\n",
      "608 %\n",
      "610 %\n",
      "613 %\n",
      "615 %\n",
      "617 %\n",
      "619 %\n",
      "621 %\n",
      "623 %\n",
      "625 %\n",
      "628 %\n",
      "630 %\n",
      "632 %\n",
      "634 %\n",
      "636 %\n",
      "638 %\n",
      "640 %\n",
      "642 %\n",
      "645 %\n",
      "647 %\n",
      "649 %\n",
      "651 %\n",
      "653 %\n",
      "655 %\n",
      "657 %\n",
      "660 %\n",
      "662 %\n",
      "664 %\n",
      "666 %\n",
      "668 %\n",
      "670 %\n",
      "672 %\n",
      "674 %\n",
      "677 %\n",
      "679 %\n",
      "681 %\n",
      "683 %\n",
      "685 %\n",
      "687 %\n",
      "689 %\n",
      "692 %\n",
      "694 %\n",
      "696 %\n",
      "698 %\n",
      "700 %\n",
      "702 %\n",
      "704 %\n",
      "707 %\n",
      "709 %\n",
      "711 %\n",
      "713 %\n",
      "715 %\n",
      "717 %\n",
      "719 %\n",
      "721 %\n",
      "724 %\n",
      "726 %\n",
      "728 %\n",
      "730 %\n",
      "732 %\n",
      "734 %\n",
      "736 %\n",
      "739 %\n",
      "741 %\n",
      "743 %\n",
      "745 %\n",
      "747 %\n",
      "749 %\n",
      "751 %\n",
      "753 %\n",
      "756 %\n",
      "758 %\n",
      "760 %\n",
      "762 %\n",
      "764 %\n",
      "766 %\n",
      "768 %\n",
      "771 %\n",
      "773 %\n",
      "775 %\n",
      "777 %\n",
      "779 %\n",
      "781 %\n",
      "783 %\n",
      "785 %\n",
      "788 %\n",
      "790 %\n",
      "792 %\n",
      "794 %\n",
      "796 %\n",
      "798 %\n",
      "800 %\n",
      "803 %\n",
      "805 %\n",
      "807 %\n",
      "809 %\n",
      "811 %\n",
      "813 %\n",
      "815 %\n",
      "818 %\n",
      "820 %\n",
      "822 %\n",
      "824 %\n",
      "826 %\n",
      "828 %\n",
      "830 %\n",
      "832 %\n",
      "835 %\n",
      "837 %\n",
      "839 %\n",
      "841 %\n",
      "843 %\n",
      "845 %\n",
      "847 %\n",
      "850 %\n",
      "852 %\n",
      "854 %\n",
      "856 %\n",
      "858 %\n",
      "860 %\n",
      "862 %\n",
      "864 %\n",
      "867 %\n",
      "869 %\n",
      "871 %\n",
      "873 %\n",
      "875 %\n",
      "877 %\n",
      "879 %\n",
      "882 %\n",
      "884 %\n",
      "886 %\n",
      "888 %\n",
      "890 %\n",
      "892 %\n",
      "894 %\n",
      "896 %\n",
      "899 %\n",
      "901 %\n",
      "903 %\n",
      "905 %\n",
      "907 %\n",
      "909 %\n",
      "911 %\n",
      "914 %\n",
      "916 %\n",
      "918 %\n",
      "920 %\n",
      "922 %\n",
      "924 %\n",
      "926 %\n",
      "928 %\n",
      "931 %\n",
      "933 %\n",
      "935 %\n",
      "937 %\n",
      "939 %\n",
      "941 %\n",
      "943 %\n",
      "946 %\n",
      "948 %\n",
      "950 %\n",
      "952 %\n",
      "954 %\n",
      "956 %\n",
      "958 %\n",
      "961 %\n",
      "963 %\n",
      "965 %\n",
      "967 %\n",
      "969 %\n",
      "971 %\n",
      "973 %\n",
      "975 %\n",
      "978 %\n",
      "980 %\n",
      "982 %\n",
      "984 %\n",
      "986 %\n",
      "988 %\n",
      "990 %\n",
      "993 %\n",
      "995 %\n",
      "997 %\n",
      "999 %\n",
      "1001 %\n",
      "1003 %\n",
      "1005 %\n",
      "1007 %\n",
      "1010 %\n",
      "1012 %\n",
      "1014 %\n",
      "1016 %\n",
      "1018 %\n",
      "1020 %\n",
      "1022 %\n",
      "1025 %\n",
      "1027 %\n",
      "1029 %\n",
      "1031 %\n",
      "1033 %\n",
      "1035 %\n",
      "1037 %\n",
      "1039 %\n",
      "1042 %\n",
      "1044 %\n",
      "1046 %\n",
      "1048 %\n",
      "1050 %\n",
      "1052 %\n",
      "1054 %\n",
      "1057 %\n",
      "1059 %\n",
      "1061 %\n",
      "1063 %\n",
      "1065 %\n",
      "1067 %\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "#TODO leverage FederatedDataset and FederatedDataloader\n",
    "\n",
    "#Load required dataset\n",
    "trainloader,testloader=Load_Data()\n",
    "\n",
    "#Distribute dataset among workers\n",
    "train_distributed_dataset = FederatedDataset(compute_nodes,trainloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Visualize Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x129ea90f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horse   car   cat  bird\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define Neural Network Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    '''Neural Network Model'''\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Net,self).__init__()\n",
    "        self.conv1=nn.Conv2d(3,6,5)\n",
    "        self.pool=nn.MaxPool2d(2,2)\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        self.fc1=nn.Linear(16*5*5,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3=nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x=self.pool(F.relu(self.conv1(x)))\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        x=x.view(-1,16*5*5)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train Network</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model,loader,optimizer,epoch):\n",
    "\n",
    "   model.train()\n",
    "   for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "      for batch_idx, (data, target) in enumerate(train_distributed_dataset): # <-- now it is a distributed dataset\n",
    "           model.send(data.location) # <-- NEW: send the model to the right location\n",
    "           #TODO data, target = data.to(device), target.to(device)\n",
    "           output = model(data)\n",
    "           loss = F.nll_loss(output, target)\n",
    "           loss.backward()\n",
    "           optimizer.step()\n",
    "           model.get() # <-- NEW: get the model back\n",
    "           if batch_idx % 1000 == 0:\n",
    "               loss = loss.get() # <-- NEW: get the loss back\n",
    "               print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                 epoch, batch_idx * args.batch_size, len(loader) * args.batch_size, #batch_idx * len(data), len(train_loader.dataset),\n",
    "                 100. * batch_idx / len(loader), loss.item()))\n",
    "                \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model,device,test_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            #TODO should be using with kwargs: output.argmax(dim=1, keepdim=True)\n",
    "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model=Net()\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.SGD(model.parameters(),lr=0.001,momentum=0.9)\n",
    "optimizer.zero_grad() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/800000 (0%)]\tLoss: 0.035673\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "add_() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-212-b6c6aeaa6a86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-204-ff47e8a1b87f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m            \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m            \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m            \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m            \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# <-- NEW: get the model back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/syft_flstm/lib/python3.6/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                         \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/syft_flstm/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/frameworks/torch/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m                 \u001b[0;31m# Send the new command to the appropriate class and get the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                 \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0;31m# For inplace methods, just directly return self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/syft_flstm/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/frameworks/torch/hook.py\u001b[0m in \u001b[0;36moverloaded_pointer_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;31m# Send the command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mcommand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/syft_flstm/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/workers/base.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, recipient, message)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \"\"\"\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMSGTYPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/syft_flstm/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/workers/base.py\u001b[0m in \u001b[0;36msend_msg\u001b[0;34m(self, msg_type, message, location)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;31m# Step 2: send the message and wait for a response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mbin_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbin_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# Step 3: deserialize the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/syft_flstm/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_send_msg\u001b[0;34m(self, message, location)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVirtualWorker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseWorker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/syft_flstm/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/workers/virtual.py\u001b[0m in \u001b[0;36m_recv_msg\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/syft_flstm/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/workers/base.py\u001b[0m in \u001b[0;36mrecv_msg\u001b[0;34m(self, bin_message)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"worker {self} received {msg_type} {contents}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# Step 1: route message to appropriate function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_router\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmsg_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# # Step 2: If response in none, set default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/syft_flstm/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/workers/base.py\u001b[0m in \u001b[0;36mexecute_command\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_self\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_inplace_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/syft_flstm/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/frameworks/torch/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;31m# we can make some errors more descriptive with this method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mroute_method_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# means that there is a wrapper to remove\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/syft_flstm/lib/python3.6/site-packages/syft-0.1.2a1-py3.6.egg/syft/frameworks/torch/hook.py\u001b[0m in \u001b[0;36moverloaded_native_method\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m                         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: add_() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(model,trainloader, optimizer, epoch)\n",
    "    test(model, device, testloader)\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(model.state_dict(), \"federated_cifar10.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
