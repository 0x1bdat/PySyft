{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Federated Learning with Remote Gradient Averaging\n",
    "\n",
    "In Part 2 of this tutorial, we trained a model using a very simple version of Federated Learning. This required each data owner to trust the model owner to be able to see their gradients. In this next tutorial, we'll show how to use the advanced aggregation tootls from Part 3 to allow the gradients to be aggregated by a trusted \"secure worker\" before the final result is sent back to the model owner (us). In this way, only the secure worker can see whose gradient came from whom. We might be able to tell which parts of the model changed, but we do NOT know which worker (bob or alice) made which change, which creates a layer of privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import copy\n",
    "hook = sy.TorchHook()\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Create Data Owners\n",
    "\n",
    "First, we're going to create two data owners (Bob and Alice) each with a small amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a couple workers\n",
    "\n",
    "bob = sy.VirtualWorker(id=\"bob\")\n",
    "alice = sy.VirtualWorker(id=\"alice\")\n",
    "secure_worker = sy.VirtualWorker(id=\"secure_worker\")\n",
    "\n",
    "bob.add_workers([alice, secure_worker])\n",
    "alice.add_workers([bob, secure_worker])\n",
    "secure_worker.add_workers([alice, bob])\n",
    "\n",
    "# A Toy Dataset\n",
    "data = sy.Var(sy.FloatTensor([[0,0],[0,1],[1,0],[1,1]]))\n",
    "target = sy.Var(sy.FloatTensor([[0],[0],[1],[1]]))\n",
    "\n",
    "# get pointers to training data on each worker by\n",
    "# sending some training data to bob and alice\n",
    "bobs_data = data[0:2].send(bob)\n",
    "bobs_target = target[0:2].send(bob)\n",
    "\n",
    "alices_data = data[2:].send(alice)\n",
    "alices_target = target[2:].send(alice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Our Model\n",
    "\n",
    "For this example, we're going to train with a simple Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniitalize A Toy Model\n",
    "model = nn.Linear(2,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send a Copy of the Model to Alice and Bob\n",
    "\n",
    "Next, we need to send a copy of the current model to Alice and Bob so that they can perform steps of learning on their own datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobs_model = model.copy().send(bob)\n",
    "alices_model = model.copy().send(alice)\n",
    "\n",
    "bobs_opt = optim.SGD(params=bobs_model.parameters(),lr=0.1)\n",
    "alices_opt = optim.SGD(params=alices_model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Bob's and Alice's Models (in parallel) for a While"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1239965483546257"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Bob's Model\n",
    "bobs_opt.zero_grad()\n",
    "bobs_pred = bobs_model(bobs_data)\n",
    "bobs_loss = ((bobs_pred - bobs_target)**2).sum()\n",
    "bobs_loss.backward()\n",
    "\n",
    "bobs_opt.step()\n",
    "bobs_loss = bobs_loss.get().data[0]\n",
    "\n",
    "# Train Alice's Model\n",
    "alices_opt.zero_grad()\n",
    "alices_pred = alices_model(alices_data)\n",
    "alices_loss = ((alices_pred - alices_target)**2).sum()\n",
    "alices_loss.backward()\n",
    "\n",
    "alices_opt.step()\n",
    "alices_loss = alices_loss.get().data[0]\n",
    "alices_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Both Updated Models to a Secure Worker (directly)\n",
    "\n",
    "Note that this use of our API means that each model is sent DIRECTLY to the secure_worker. We never see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=1, bias=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alices_model.send(secure_worker).end_get()\n",
    "bobs_model.send(secure_worker).end_get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.3455\n",
       "[syft.core.frameworks.torch.tensor.FloatTensor of size 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight.data.set_(((alices_model.weight.data + bobs_model.weight.data) / 2).get())\n",
    "model.bias.data.set_(((alices_model.bias.data + bobs_model.bias.data) / 2).get())\n",
    "\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rinse and Repeat\n",
    "\n",
    "And now we just need to iterate this multiple times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bob:0.004386157263070345 Alice:0.0008877946529537439\n",
      "Bob:0.0032940830569714308 Alice:0.00020828367269132286\n",
      "Bob:0.002606127178296447 Alice:0.0001087550917873159\n",
      "Bob:0.0020534354262053967 Alice:7.037258183117956e-05\n",
      "Bob:0.0016087408876046538 Alice:4.832143895328045e-05\n",
      "Bob:0.0012546723010018468 Alice:3.412826845305972e-05\n",
      "Bob:0.0009752266923896968 Alice:2.458133349136915e-05\n",
      "Bob:0.000756114604882896 Alice:1.7976701201405376e-05\n",
      "Bob:0.0005851347232237458 Alice:1.3303907508088741e-05\n",
      "Bob:0.0004521861847024411 Alice:9.93773755908478e-06\n"
     ]
    }
   ],
   "source": [
    "iterations = 10\n",
    "worker_iters = 5\n",
    "\n",
    "for a_iter in range(iterations):\n",
    "    \n",
    "    bobs_model = model.copy().send(bob)\n",
    "    alices_model = model.copy().send(alice)\n",
    "\n",
    "    bobs_opt = optim.SGD(params=bobs_model.parameters(),lr=0.1)\n",
    "    alices_opt = optim.SGD(params=alices_model.parameters(),lr=0.1)\n",
    "\n",
    "    for wi in range(worker_iters):\n",
    "\n",
    "        # Train Bob's Model\n",
    "        bobs_opt.zero_grad()\n",
    "        bobs_pred = bobs_model(bobs_data)\n",
    "        bobs_loss = ((bobs_pred - bobs_target)**2).sum()\n",
    "        bobs_loss.backward()\n",
    "\n",
    "        bobs_opt.step()\n",
    "        bobs_loss = bobs_loss.get().data[0]\n",
    "\n",
    "        # Train Alice's Model\n",
    "        alices_opt.zero_grad()\n",
    "        alices_pred = alices_model(alices_data)\n",
    "        alices_loss = ((alices_pred - alices_target)**2).sum()\n",
    "        alices_loss.backward()\n",
    "\n",
    "        alices_opt.step()\n",
    "        alices_loss = alices_loss.get().data[0]\n",
    "    \n",
    "    alices_model.send(secure_worker).end_get()\n",
    "    bobs_model.send(secure_worker).end_get()\n",
    "    \n",
    "    model.weight.data.set_(((alices_model.weight.data + bobs_model.weight.data) / 2).get())\n",
    "    model.bias.data.set_(((alices_model.bias.data + bobs_model.bias.data) / 2).get())\n",
    "    \n",
    "    print(\"Bob:\" + str(bobs_loss) + \" Alice:\" + str(alices_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
