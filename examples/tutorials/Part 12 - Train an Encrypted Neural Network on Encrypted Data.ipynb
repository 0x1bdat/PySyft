{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 12: Train an Encrypted NN on Encrypted Data\n",
    "\n",
    "In this notebook, we're going to use all the techniques we've learned thus far to perform neural network training (and prediction) while both the model and the data are encrypted.\n",
    "\n",
    "Note that Autograd is not *yet* supported for encrypted variables, thus we'll have to roll our own gradients ourselves. This functionality will be added in the next PySyft version.\n",
    "\n",
    "Authors:\n",
    "- Andrew Trask - Twitter: [@iamtrask](https://twitter.com/iamtrask)\n",
    "- Jason Paumier - Github: [@Jasopaum](https://github.com/Jasopaum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Create Workers and Toy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set everything up\n",
    "hook = sy.TorchHook(torch) \n",
    "\n",
    "alice = sy.VirtualWorker(id=\"alice\", hook=hook)\n",
    "bob = sy.VirtualWorker(id=\"bob\", hook=hook)\n",
    "james = sy.VirtualWorker(id=\"james\", hook=hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our dataset\n",
    "\n",
    "data = torch.Tensor([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
    "target = torch.Tensor([[0.], [0.], [1.], [1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our model\n",
    "# We use a small linear model: M.X = y\n",
    "# where M is the mdoel, X is the data, and y the prediction\n",
    "\n",
    "model = torch.Tensor([[0.], [0.]])\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Encrypt the Model and Data\n",
    "\n",
    "Encryption here comes in two steps. Since Secure Multi-Party Computation only works on Longs, in order to operate over numbers with decimal points (such as weights and activations), we need to encode all of our numbers using Fixed Precision, which will give us several bits of floating point precision. We do this by calling .fix_precision().\n",
    "\n",
    "We can then call .share() as we have for other demos, which will encrypt all of the values by sharing them between Alice and Bob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We encode everything\n",
    "prec_frac = 2\n",
    "\n",
    "data_enc = data.fix_precision(precision_fractional=prec_frac).share(alice, bob, crypto_provider=james)\n",
    "target_enc = target.fix_precision(precision_fractional=prec_frac).share(alice, bob, crypto_provider=james)\n",
    "model_enc = model.fix_precision(precision_fractional=prec_frac).share(alice, bob, crypto_provider=james)\n",
    "\n",
    "# The learning rate is also changed to fixed precision\n",
    "learning_rate_fp = torch.tensor(learning_rate).fix_precision(precision_fractional=prec_frac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Train\n",
    "\n",
    "And now we can train using simple tensor logic. Note that autograd is not yet supported (but it will be in the Torch 1.0 refactor which you can [watch here](https://github.com/OpenMined/PySyft/issues/1587))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:22406171387 -> alice:28323756150], 'bob': (Wrapper)>[PointerTensor | me:97718244538 -> bob:35886260787]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([2.])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:67500623698 -> alice:81757808369], 'bob': (Wrapper)>[PointerTensor | me:29593827223 -> bob:16479130358]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([1.6000])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:63735358614 -> alice:1028675112], 'bob': (Wrapper)>[PointerTensor | me:98735404593 -> bob:90770182299]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([1.3000])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:34752760639 -> alice:60234838606], 'bob': (Wrapper)>[PointerTensor | me:50272365042 -> bob:26772812228]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([1.0600])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:75918384151 -> alice:5512535435], 'bob': (Wrapper)>[PointerTensor | me:97354276596 -> bob:94605523603]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([0.8800])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:59971563483 -> alice:52881272976], 'bob': (Wrapper)>[PointerTensor | me:63973777614 -> bob:54965722454]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([0.7400])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:89247216757 -> alice:20080034163], 'bob': (Wrapper)>[PointerTensor | me:3530229918 -> bob:73200048937]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([0.6200])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:79197990868 -> alice:87475113624], 'bob': (Wrapper)>[PointerTensor | me:32419235970 -> bob:10878313882]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([0.5400])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:45471941011 -> alice:48397454967], 'bob': (Wrapper)>[PointerTensor | me:87896938104 -> bob:31239664565]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([0.4600])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:78373523481 -> alice:52877282735], 'bob': (Wrapper)>[PointerTensor | me:213208013 -> bob:94207989082]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([0.4000])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:83647930378 -> alice:63154747741], 'bob': (Wrapper)>[PointerTensor | me:36079886064 -> bob:23402786086]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([0.3600])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:44094994445 -> alice:62164699974], 'bob': (Wrapper)>[PointerTensor | me:56581002283 -> bob:62596839914]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([0.3200])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:30223205522 -> alice:7189670187], 'bob': (Wrapper)>[PointerTensor | me:28490724327 -> bob:72197551014]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([0.2800])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:89595900458 -> alice:67858749286], 'bob': (Wrapper)>[PointerTensor | me:67795714418 -> bob:32553321755]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([0.2600])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:19424089102 -> alice:36952159897], 'bob': (Wrapper)>[PointerTensor | me:42920200586 -> bob:6363158865]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([0.2400])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:56486233986 -> alice:72557246303], 'bob': (Wrapper)>[PointerTensor | me:65611757847 -> bob:56568487050]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([0.2200])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:57530244755 -> alice:36569915926], 'bob': (Wrapper)>[PointerTensor | me:10876210744 -> bob:23744386661]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([0.2000])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:88014727893 -> alice:81740215437], 'bob': (Wrapper)>[PointerTensor | me:33476980077 -> bob:63634699474]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([0.1800])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:15420320567 -> alice:4932622102], 'bob': (Wrapper)>[PointerTensor | me:29644734503 -> bob:41627978365]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([0.1600])\n",
      "===\n",
      "{'alice': (Wrapper)>[PointerTensor | me:34604393996 -> alice:20893194427], 'bob': (Wrapper)>[PointerTensor | me:61711091102 -> bob:59405129048]}\n",
      "tensor([10])\n",
      "___\n",
      "tensor([0.1400])\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    # Use the model to predict\n",
    "    pred = data_enc.matmul(model_enc)\n",
    "    # How much is the model wrong\n",
    "    err = pred - target_enc\n",
    "    # Compute gradient descent step\n",
    "    update = data_enc.t().matmul(err)\n",
    "    # Apply the gradient descent step\n",
    "    model_enc = model_enc - update * learning_rate_fp\n",
    "    \n",
    "    loss = err.get().abs().sum().float_precision()\n",
    "    print(loss) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss indeed decreased.\n",
    "\n",
    "We can also verify that the model is close to what we could have expected (the task was to output the value of the first dimension of the input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9400],\n",
       "        [0.0600]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_enc.get().float_precision()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!!! - Time to Join the Community!\n",
    "\n",
    "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways!\n",
    "\n",
    "### Star PySyft on Github\n",
    "\n",
    "The easiest way to help our community is just by starring the Repos! This helps raise awareness of the cool tools we're building.\n",
    "\n",
    "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
    "\n",
    "### Join our Slack!\n",
    "\n",
    "The best way to keep up to date on the latest advancements is to join our community! You can do so by filling out the form at [http://slack.openmined.org](http://slack.openmined.org)\n",
    "\n",
    "### Join a Code Project!\n",
    "\n",
    "The best way to contribute to our community is to become a code contributor! At any time you can go to PySyft Github Issues page and filter for \"Projects\". This will show you all the top level Tickets giving an overview of what projects you can join! If you don't want to join a project, but you would like to do a bit of coding, you can also look for more \"one off\" mini-projects by searching for github issues marked \"good first issue\".\n",
    "\n",
    "- [PySyft Projects](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
    "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
    "\n",
    "### Donate\n",
    "\n",
    "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
    "\n",
    "[OpenMined's Open Collective Page](https://opencollective.com/openmined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
